{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('UNSW_NB15_training-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=80000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 45)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal            25517\n",
       "Generic           18357\n",
       "Exploits          15139\n",
       "Fuzzers            8261\n",
       "DoS                5528\n",
       "Reconnaissance     4835\n",
       "Analysis            928\n",
       "Backdoor            853\n",
       "Shellcode           516\n",
       "Worms                66\n",
       "Name: attack_cat, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.attack_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 categorical variables\n",
      "\n",
      "The categorical variables are : ['proto', 'service', 'state', 'attack_cat']\n",
      "proto  contains  132  labels\n",
      "service  contains  13  labels\n",
      "state  contains  6  labels\n",
      "attack_cat  contains  10  labels\n"
     ]
    }
   ],
   "source": [
    "# find categorical variables\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "print('The categorical variables are :', categorical)\n",
    "# check for cardinality in categorical variables\n",
    "for var in categorical:    \n",
    "    print(var, ' contains ', len(df[var].unique()), ' labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "df['proto'] = df['proto'].astype('category')\n",
    "df['service'] = df['service'].astype('category')\n",
    "df['state'] = df['state'].astype('category')\n",
    "df['attack_cat'] = df['attack_cat'].astype('category')\n",
    "cat_columns = df.select_dtypes(['category']).columns\n",
    "df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = df.columns[categorical_feature_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, df.columns!='attack_cat']\n",
    "Y = df.iloc[:, 43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_inputed = ['id',\n",
    " 'dur',\n",
    " 'proto',\n",
    " 'service',\n",
    " 'state',\n",
    " 'spkts',\n",
    " 'dpkts',\n",
    " 'sbytes',\n",
    " 'dbytes',\n",
    " 'rate',\n",
    " 'sttl',\n",
    " 'dttl',\n",
    " 'sload',\n",
    " 'dload',\n",
    " 'sloss',\n",
    " 'dloss',\n",
    " 'sinpkt',\n",
    " 'dinpkt',\n",
    " 'sjit',\n",
    " 'djit',\n",
    " 'swin',\n",
    " 'stcpb',\n",
    " 'dtcpb',\n",
    " 'dwin',\n",
    " 'tcprtt',\n",
    " 'synack',\n",
    " 'ackdat',\n",
    " 'smean',\n",
    " 'dmean',\n",
    " 'trans_depth',\n",
    " 'response_body_len',\n",
    " 'ct_srv_src',\n",
    " 'ct_state_ttl',\n",
    " 'ct_dst_ltm',\n",
    " 'ct_src_dport_ltm',\n",
    " 'ct_dst_sport_ltm',\n",
    " 'ct_dst_src_ltm',\n",
    " 'is_ftp_login',\n",
    " 'ct_ftp_cmd',\n",
    " 'ct_flw_http_mthd',\n",
    " 'ct_src_ltm',\n",
    " 'ct_srv_dst',\n",
    " 'is_sm_ips_ports',\n",
    " 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sScaler = StandardScaler()\n",
    "rescaleX = sScaler.fit_transform(X)\n",
    "df_rescaled = pd.DataFrame(data=rescaleX, columns=names_inputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm = Normalizer()\n",
    "xNormalize = norm.fit_transform(X)\n",
    "df_Normalized = pd.DataFrame(data=xNormalize, columns=names_inputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(rescaleX, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56000/56000 [==============================] - 15s 273us/step - loss: 0.7240 - accuracy: 0.7374\n",
      "Epoch 2/100\n",
      "56000/56000 [==============================] - 16s 286us/step - loss: 0.5728 - accuracy: 0.7878\n",
      "Epoch 3/100\n",
      "56000/56000 [==============================] - 16s 282us/step - loss: 0.5207 - accuracy: 0.8069\n",
      "Epoch 4/100\n",
      "56000/56000 [==============================] - 16s 283us/step - loss: 0.4829 - accuracy: 0.8251\n",
      "Epoch 5/100\n",
      "56000/56000 [==============================] - 15s 262us/step - loss: 0.4619 - accuracy: 0.8326\n",
      "Epoch 6/100\n",
      "56000/56000 [==============================] - 13s 240us/step - loss: 0.4487 - accuracy: 0.8361\n",
      "Epoch 7/100\n",
      "56000/56000 [==============================] - 14s 242us/step - loss: 0.4430 - accuracy: 0.8389s -\n",
      "Epoch 8/100\n",
      "56000/56000 [==============================] - 13s 239us/step - loss: 0.4370 - accuracy: 0.8394\n",
      "Epoch 9/100\n",
      "56000/56000 [==============================] - 14s 245us/step - loss: 0.4340 - accuracy: 0.8412\n",
      "Epoch 10/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4313 - accuracy: 0.8418\n",
      "Epoch 11/100\n",
      "56000/56000 [==============================] - 14s 250us/step - loss: 0.4271 - accuracy: 0.8445\n",
      "Epoch 12/100\n",
      "56000/56000 [==============================] - 15s 265us/step - loss: 0.4254 - accuracy: 0.8443\n",
      "Epoch 13/100\n",
      "56000/56000 [==============================] - 15s 262us/step - loss: 0.4226 - accuracy: 0.8446\n",
      "Epoch 14/100\n",
      "56000/56000 [==============================] - 15s 264us/step - loss: 0.4232 - accuracy: 0.8458\n",
      "Epoch 15/100\n",
      "56000/56000 [==============================] - 15s 264us/step - loss: 0.4187 - accuracy: 0.8459\n",
      "Epoch 16/100\n",
      "56000/56000 [==============================] - 15s 266us/step - loss: 0.4192 - accuracy: 0.8473\n",
      "Epoch 17/100\n",
      "56000/56000 [==============================] - 15s 262us/step - loss: 0.4179 - accuracy: 0.8467\n",
      "Epoch 18/100\n",
      "56000/56000 [==============================] - 15s 265us/step - loss: 0.4164 - accuracy: 0.8472\n",
      "Epoch 19/100\n",
      "56000/56000 [==============================] - 15s 264us/step - loss: 0.4178 - accuracy: 0.8468\n",
      "Epoch 20/100\n",
      "56000/56000 [==============================] - 15s 264us/step - loss: 0.4158 - accuracy: 0.8485\n",
      "Epoch 21/100\n",
      "56000/56000 [==============================] - 15s 266us/step - loss: 0.4160 - accuracy: 0.8478\n",
      "Epoch 22/100\n",
      "56000/56000 [==============================] - 15s 265us/step - loss: 0.4144 - accuracy: 0.8489\n",
      "Epoch 23/100\n",
      "56000/56000 [==============================] - 15s 266us/step - loss: 0.4128 - accuracy: 0.8488\n",
      "Epoch 24/100\n",
      "56000/56000 [==============================] - 15s 266us/step - loss: 0.4127 - accuracy: 0.8487\n",
      "Epoch 25/100\n",
      "56000/56000 [==============================] - 15s 269us/step - loss: 0.4108 - accuracy: 0.8498\n",
      "Epoch 26/100\n",
      "56000/56000 [==============================] - 15s 269us/step - loss: 0.4116 - accuracy: 0.8480\n",
      "Epoch 27/100\n",
      "56000/56000 [==============================] - 15s 268us/step - loss: 0.4112 - accuracy: 0.8496\n",
      "Epoch 28/100\n",
      "56000/56000 [==============================] - 15s 270us/step - loss: 0.4107 - accuracy: 0.8496\n",
      "Epoch 29/100\n",
      "56000/56000 [==============================] - 15s 273us/step - loss: 0.4132 - accuracy: 0.8490\n",
      "Epoch 30/100\n",
      "56000/56000 [==============================] - 15s 264us/step - loss: 0.4102 - accuracy: 0.8489\n",
      "Epoch 31/100\n",
      "56000/56000 [==============================] - 15s 264us/step - loss: 0.4100 - accuracy: 0.8516\n",
      "Epoch 32/100\n",
      "56000/56000 [==============================] - 15s 265us/step - loss: 0.4093 - accuracy: 0.8501\n",
      "Epoch 33/100\n",
      "56000/56000 [==============================] - 15s 264us/step - loss: 0.4088 - accuracy: 0.8501\n",
      "Epoch 34/100\n",
      "56000/56000 [==============================] - 15s 270us/step - loss: 0.4110 - accuracy: 0.8491\n",
      "Epoch 35/100\n",
      "56000/56000 [==============================] - 15s 265us/step - loss: 0.4075 - accuracy: 0.8510\n",
      "Epoch 36/100\n",
      "56000/56000 [==============================] - 15s 266us/step - loss: 0.4067 - accuracy: 0.8507\n",
      "Epoch 37/100\n",
      "56000/56000 [==============================] - 15s 266us/step - loss: 0.4077 - accuracy: 0.8508\n",
      "Epoch 38/100\n",
      "56000/56000 [==============================] - 15s 271us/step - loss: 0.4068 - accuracy: 0.8507\n",
      "Epoch 39/100\n",
      "56000/56000 [==============================] - 15s 269us/step - loss: 0.4069 - accuracy: 0.8506\n",
      "Epoch 40/100\n",
      "56000/56000 [==============================] - 15s 268us/step - loss: 0.4074 - accuracy: 0.8512\n",
      "Epoch 41/100\n",
      "56000/56000 [==============================] - 15s 267us/step - loss: 0.4062 - accuracy: 0.8507\n",
      "Epoch 42/100\n",
      "56000/56000 [==============================] - 15s 270us/step - loss: 0.4056 - accuracy: 0.8518\n",
      "Epoch 43/100\n",
      "56000/56000 [==============================] - 15s 269us/step - loss: 0.4058 - accuracy: 0.8503\n",
      "Epoch 44/100\n",
      "56000/56000 [==============================] - 15s 268us/step - loss: 0.4050 - accuracy: 0.8511\n",
      "Epoch 45/100\n",
      "56000/56000 [==============================] - 15s 269us/step - loss: 0.4057 - accuracy: 0.8503\n",
      "Epoch 46/100\n",
      "56000/56000 [==============================] - 15s 269us/step - loss: 0.4059 - accuracy: 0.8514\n",
      "Epoch 47/100\n",
      "56000/56000 [==============================] - 15s 270us/step - loss: 0.4042 - accuracy: 0.8526\n",
      "Epoch 48/100\n",
      "56000/56000 [==============================] - 15s 267us/step - loss: 0.4054 - accuracy: 0.8521\n",
      "Epoch 49/100\n",
      "56000/56000 [==============================] - 15s 268us/step - loss: 0.4076 - accuracy: 0.8511\n",
      "Epoch 50/100\n",
      "56000/56000 [==============================] - 15s 269us/step - loss: 0.4058 - accuracy: 0.8519\n",
      "Epoch 51/100\n",
      "56000/56000 [==============================] - 15s 270us/step - loss: 0.4058 - accuracy: 0.8522\n",
      "Epoch 52/100\n",
      "56000/56000 [==============================] - 15s 267us/step - loss: 0.4043 - accuracy: 0.8523\n",
      "Epoch 53/100\n",
      "56000/56000 [==============================] - 15s 267us/step - loss: 0.4061 - accuracy: 0.8513\n",
      "Epoch 54/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4045 - accuracy: 0.8514\n",
      "Epoch 55/100\n",
      "56000/56000 [==============================] - 14s 253us/step - loss: 0.4051 - accuracy: 0.8524\n",
      "Epoch 56/100\n",
      "56000/56000 [==============================] - 14s 258us/step - loss: 0.4070 - accuracy: 0.8516\n",
      "Epoch 57/100\n",
      "56000/56000 [==============================] - 14s 253us/step - loss: 0.4043 - accuracy: 0.8509\n",
      "Epoch 58/100\n",
      "56000/56000 [==============================] - 15s 259us/step - loss: 0.4061 - accuracy: 0.8524\n",
      "Epoch 59/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4042 - accuracy: 0.8528\n",
      "Epoch 60/100\n",
      "56000/56000 [==============================] - 14s 257us/step - loss: 0.4053 - accuracy: 0.8517\n",
      "Epoch 61/100\n",
      "56000/56000 [==============================] - 14s 259us/step - loss: 0.4049 - accuracy: 0.8515\n",
      "Epoch 62/100\n",
      "56000/56000 [==============================] - 14s 258us/step - loss: 0.4043 - accuracy: 0.8523\n",
      "Epoch 63/100\n",
      "56000/56000 [==============================] - 15s 259us/step - loss: 0.4034 - accuracy: 0.8529\n",
      "Epoch 64/100\n",
      "56000/56000 [==============================] - 14s 258us/step - loss: 0.4047 - accuracy: 0.8535\n",
      "Epoch 65/100\n",
      "56000/56000 [==============================] - 15s 260us/step - loss: 0.4051 - accuracy: 0.8536\n",
      "Epoch 66/100\n",
      "56000/56000 [==============================] - 14s 258us/step - loss: 0.4029 - accuracy: 0.8529\n",
      "Epoch 67/100\n",
      "56000/56000 [==============================] - 14s 256us/step - loss: 0.4042 - accuracy: 0.8518\n",
      "Epoch 68/100\n",
      "56000/56000 [==============================] - 15s 264us/step - loss: 0.4026 - accuracy: 0.8532\n",
      "Epoch 69/100\n",
      "56000/56000 [==============================] - 14s 257us/step - loss: 0.4040 - accuracy: 0.8516\n",
      "Epoch 70/100\n",
      "56000/56000 [==============================] - 14s 258us/step - loss: 0.4046 - accuracy: 0.8523\n",
      "Epoch 71/100\n",
      "56000/56000 [==============================] - 14s 256us/step - loss: 0.4038 - accuracy: 0.8536\n",
      "Epoch 72/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4040 - accuracy: 0.8523\n",
      "Epoch 73/100\n",
      "56000/56000 [==============================] - 15s 274us/step - loss: 0.4038 - accuracy: 0.8535\n",
      "Epoch 74/100\n",
      "56000/56000 [==============================] - 15s 270us/step - loss: 0.4044 - accuracy: 0.8536\n",
      "Epoch 75/100\n",
      "56000/56000 [==============================] - 15s 269us/step - loss: 0.4025 - accuracy: 0.8535\n",
      "Epoch 76/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4008 - accuracy: 0.8540\n",
      "Epoch 77/100\n",
      "56000/56000 [==============================] - 14s 250us/step - loss: 0.4015 - accuracy: 0.8540\n",
      "Epoch 78/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4025 - accuracy: 0.8538\n",
      "Epoch 79/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4036 - accuracy: 0.8544\n",
      "Epoch 80/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4026 - accuracy: 0.8537\n",
      "Epoch 81/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4031 - accuracy: 0.8527\n",
      "Epoch 82/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4036 - accuracy: 0.8539\n",
      "Epoch 83/100\n",
      "56000/56000 [==============================] - 14s 257us/step - loss: 0.4026 - accuracy: 0.8550\n",
      "Epoch 84/100\n",
      "56000/56000 [==============================] - 16s 287us/step - loss: 0.4016 - accuracy: 0.8537\n",
      "Epoch 85/100\n",
      "56000/56000 [==============================] - 20s 357us/step - loss: 0.4025 - accuracy: 0.8537\n",
      "Epoch 86/100\n",
      "56000/56000 [==============================] - 20s 355us/step - loss: 0.4020 - accuracy: 0.8544\n",
      "Epoch 87/100\n",
      "56000/56000 [==============================] - 20s 361us/step - loss: 0.4013 - accuracy: 0.8535\n",
      "Epoch 88/100\n",
      "56000/56000 [==============================] - 20s 349us/step - loss: 0.4026 - accuracy: 0.8549\n",
      "Epoch 89/100\n",
      "56000/56000 [==============================] - 20s 353us/step - loss: 0.4028 - accuracy: 0.8552\n",
      "Epoch 90/100\n",
      "56000/56000 [==============================] - 20s 355us/step - loss: 0.4061 - accuracy: 0.8539\n",
      "Epoch 91/100\n",
      "56000/56000 [==============================] - 20s 353us/step - loss: 0.4013 - accuracy: 0.8542\n",
      "Epoch 92/100\n",
      "56000/56000 [==============================] - 20s 353us/step - loss: 0.4021 - accuracy: 0.8538\n",
      "Epoch 93/100\n",
      "56000/56000 [==============================] - 20s 357us/step - loss: 0.4009 - accuracy: 0.8539\n",
      "Epoch 94/100\n",
      "56000/56000 [==============================] - 20s 354us/step - loss: 0.4009 - accuracy: 0.8539\n",
      "Epoch 95/100\n",
      "56000/56000 [==============================] - 20s 353us/step - loss: 0.4052 - accuracy: 0.8554\n",
      "Epoch 96/100\n",
      "56000/56000 [==============================] - 20s 355us/step - loss: 0.4073 - accuracy: 0.8542\n",
      "Epoch 97/100\n",
      "56000/56000 [==============================] - 20s 353us/step - loss: 0.4049 - accuracy: 0.8543\n",
      "Epoch 98/100\n",
      "56000/56000 [==============================] - 20s 352us/step - loss: 0.4038 - accuracy: 0.8556\n",
      "Epoch 99/100\n",
      "56000/56000 [==============================] - 20s 353us/step - loss: 0.4038 - accuracy: 0.8553\n",
      "Epoch 100/100\n",
      "56000/56000 [==============================] - 20s 359us/step - loss: 0.4006 - accuracy: 0.8551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e61a003da0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising the Artificial Neural Network\n",
    "model = Sequential()\n",
    "#Creating the Input-layer and the first hidden layer\n",
    "model.add(Dense(400, input_dim=44, activation='sigmoid'))\n",
    "model.add(Dense(800, input_dim=44, activation='sigmoid'))\n",
    "model.add(Dense(800, input_dim=44, activation='sigmoid'))\n",
    "model.add(Dense(400, input_dim=44, activation='sigmoid'))\n",
    "#Creating the output  layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#Compiling the ANN classifier\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 3s 119us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4308823263148467, 0.8480833172798157]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "con = metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82191781, 0.        , 0.36453202, 0.7055989 , 0.84796238,\n",
       "       0.98821146, 1.        , 0.85185185, 0.55555556,        nan])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = np.diag(con) / (np.diag(con) +(con.sum(axis=0) - np.diag(con)))\n",
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.532849723225898"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = np.diag(con)/ ((con.sum(axis=1) - np.diag(con)) + np.diag(con))\n",
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.3030303 ,        nan, 0.44007319, 0.6905457 , 0.86283892,\n",
       "       0.98594138, 0.99967322, 0.77094972, 0.42654028,        nan])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#InfoGainAtributeEval\n",
    "features = ['sttl','ct_state_ttl','ct_flw_http_mthd','sbytes','id','smean','sload','dur','sinpkt','rate','proto','ct_dst_src_ltm','service','dbytes','sjit','ct_srv_dst','dload','dinpkt','dmean','ct_srv_src','synack','tcprtt','ct_dst_sport_ltm','djit','ct_src_dport_ltm','dtcpb','stcpb','spkts','dloss','ct_dst_ltm','ackdat','label','dpkts','ct_src_ltm','sloss']\n",
    "X2 = df[['sttl','ct_state_ttl','ct_flw_http_mthd','sbytes','id','smean','sload','dur','sinpkt','rate','proto','ct_dst_src_ltm','service','dbytes','sjit','ct_srv_dst','dload','dinpkt','dmean','ct_srv_src','synack','tcprtt','ct_dst_sport_ltm','djit','ct_src_dport_ltm','dtcpb','stcpb','spkts','dloss','ct_dst_ltm','ackdat','label','dpkts','ct_src_ltm','sloss']]\n",
    "Y2 = df[['attack_cat']]\n",
    "X3 = X2.iloc[:,0:35]  #independent columns\n",
    "Y3 = Y2.iloc[:,-1]    #target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sScaler = StandardScaler()\n",
    "rescaleX3 = sScaler.fit_transform(X3)\n",
    "df_rescaled = pd.DataFrame(data=rescaleX3, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rescaleX3, Y3, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56000/56000 [==============================] - 16s 282us/step - loss: 0.7354 - accuracy: 0.7328s - ETA: 1s - loss: 0.7474 - accuracy\n",
      "Epoch 2/100\n",
      "56000/56000 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.78 - 15s 270us/step - loss: 0.5784 - accuracy: 0.7865\n",
      "Epoch 3/100\n",
      "56000/56000 [==============================] - 16s 289us/step - loss: 0.5363 - accuracy: 0.8020\n",
      "Epoch 4/100\n",
      "56000/56000 [==============================] - 17s 304us/step - loss: 0.5043 - accuracy: 0.8175\n",
      "Epoch 5/100\n",
      "56000/56000 [==============================] - 16s 294us/step - loss: 0.4820 - accuracy: 0.8265\n",
      "Epoch 6/100\n",
      "56000/56000 [==============================] - 17s 295us/step - loss: 0.4666 - accuracy: 0.8318s - loss: 0.4670 - \n",
      "Epoch 7/100\n",
      "56000/56000 [==============================] - 17s 296us/step - loss: 0.4546 - accuracy: 0.8353\n",
      "Epoch 8/100\n",
      "56000/56000 [==============================] - 17s 301us/step - loss: 0.4461 - accuracy: 0.8371\n",
      "Epoch 9/100\n",
      "56000/56000 [==============================] - 17s 295us/step - loss: 0.4393 - accuracy: 0.8387\n",
      "Epoch 10/100\n",
      "56000/56000 [==============================] - 17s 296us/step - loss: 0.4382 - accuracy: 0.8401s - loss:\n",
      "Epoch 11/100\n",
      "56000/56000 [==============================] - 17s 298us/step - loss: 0.4331 - accuracy: 0.8426\n",
      "Epoch 12/100\n",
      "56000/56000 [==============================] - 17s 298us/step - loss: 0.4303 - accuracy: 0.8424s - loss: 0.4305 - accuracy\n",
      "Epoch 13/100\n",
      "56000/56000 [==============================] - 17s 297us/step - loss: 0.4292 - accuracy: 0.8428\n",
      "Epoch 14/100\n",
      "56000/56000 [==============================] - 17s 296us/step - loss: 0.4290 - accuracy: 0.8426\n",
      "Epoch 15/100\n",
      "56000/56000 [==============================] - 17s 297us/step - loss: 0.4256 - accuracy: 0.8446s - loss: 0 - ETA: 0s - loss: 0.4255 - ac\n",
      "Epoch 16/100\n",
      "56000/56000 [==============================] - 18s 320us/step - loss: 0.4239 - accuracy: 0.8465\n",
      "Epoch 17/100\n",
      "56000/56000 [==============================] - 18s 316us/step - loss: 0.4222 - accuracy: 0.8460s - loss: 0.4211 - accu\n",
      "Epoch 18/100\n",
      "56000/56000 [==============================] - 18s 313us/step - loss: 0.4225 - accuracy: 0.8445\n",
      "Epoch 19/100\n",
      "56000/56000 [==============================] - 18s 320us/step - loss: 0.4202 - accuracy: 0.8453s - los - ETA: 0s - loss:\n",
      "Epoch 20/100\n",
      "56000/56000 [==============================] - 18s 321us/step - loss: 0.4204 - accuracy: 0.8459\n",
      "Epoch 21/100\n",
      "56000/56000 [==============================] - 18s 317us/step - loss: 0.4191 - accuracy: 0.8458\n",
      "Epoch 22/100\n",
      "56000/56000 [==============================] - 17s 312us/step - loss: 0.4181 - accuracy: 0.8466s - loss:\n",
      "Epoch 23/100\n",
      "56000/56000 [==============================] - 17s 308us/step - loss: 0.4173 - accuracy: 0.8468s - loss: 0.4167 - accura\n",
      "Epoch 24/100\n",
      "56000/56000 [==============================] - 14s 253us/step - loss: 0.4161 - accuracy: 0.8479\n",
      "Epoch 25/100\n",
      "56000/56000 [==============================] - 14s 254us/step - loss: 0.4161 - accuracy: 0.8466\n",
      "Epoch 26/100\n",
      "56000/56000 [==============================] - 14s 253us/step - loss: 0.4147 - accuracy: 0.8469\n",
      "Epoch 27/100\n",
      "56000/56000 [==============================] - 14s 253us/step - loss: 0.4144 - accuracy: 0.8486\n",
      "Epoch 28/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4131 - accuracy: 0.8491s - loss: 0.4125 \n",
      "Epoch 29/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4129 - accuracy: 0.8481\n",
      "Epoch 30/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4128 - accuracy: 0.8487\n",
      "Epoch 31/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4124 - accuracy: 0.8477\n",
      "Epoch 32/100\n",
      "56000/56000 [==============================] - 14s 256us/step - loss: 0.4132 - accuracy: 0.8499s - loss: 0.4132 - accuracy: 0.84\n",
      "Epoch 33/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4111 - accuracy: 0.8496s\n",
      "Epoch 34/100\n",
      "56000/56000 [==============================] - 14s 253us/step - loss: 0.4108 - accuracy: 0.8497\n",
      "Epoch 35/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4126 - accuracy: 0.8505\n",
      "Epoch 36/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4103 - accuracy: 0.8490s - loss: 0.4100 - accura\n",
      "Epoch 37/100\n",
      "56000/56000 [==============================] - 14s 254us/step - loss: 0.4084 - accuracy: 0.8509\n",
      "Epoch 38/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4107 - accuracy: 0.8506\n",
      "Epoch 39/100\n",
      "56000/56000 [==============================] - 14s 253us/step - loss: 0.4098 - accuracy: 0.8501\n",
      "Epoch 40/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4105 - accuracy: 0.8496\n",
      "Epoch 41/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4102 - accuracy: 0.8499s - loss: 0.4099 - accuracy: 0.85\n",
      "Epoch 42/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4066 - accuracy: 0.8511\n",
      "Epoch 43/100\n",
      "56000/56000 [==============================] - 14s 245us/step - loss: 0.4104 - accuracy: 0.8502\n",
      "Epoch 44/100\n",
      "56000/56000 [==============================] - 13s 240us/step - loss: 0.4073 - accuracy: 0.8502\n",
      "Epoch 45/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4092 - accuracy: 0.8512\n",
      "Epoch 46/100\n",
      "56000/56000 [==============================] - 15s 268us/step - loss: 0.4076 - accuracy: 0.8501\n",
      "Epoch 47/100\n",
      "56000/56000 [==============================] - 15s 259us/step - loss: 0.4072 - accuracy: 0.8503s - loss: - ETA: 0s - loss: 0.4074 - accuracy:  - ETA: 0s - loss: 0.4075 - accuracy\n",
      "Epoch 48/100\n",
      "56000/56000 [==============================] - 14s 244us/step - loss: 0.4068 - accuracy: 0.8514\n",
      "Epoch 49/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4080 - accuracy: 0.8509\n",
      "Epoch 50/100\n",
      "56000/56000 [==============================] - 15s 261us/step - loss: 0.4070 - accuracy: 0.8511\n",
      "Epoch 51/100\n",
      "56000/56000 [==============================] - 14s 248us/step - loss: 0.4074 - accuracy: 0.8509\n",
      "Epoch 52/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4056 - accuracy: 0.8497s - loss: 0.4057 - accuracy: \n",
      "Epoch 53/100\n",
      "56000/56000 [==============================] - 14s 247us/step - loss: 0.4075 - accuracy: 0.8517\n",
      "Epoch 54/100\n",
      "56000/56000 [==============================] - 14s 248us/step - loss: 0.4043 - accuracy: 0.8521\n",
      "Epoch 55/100\n",
      "56000/56000 [==============================] - 14s 248us/step - loss: 0.4051 - accuracy: 0.8498s - loss: 0.4053 - accuracy\n",
      "Epoch 56/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4057 - accuracy: 0.8531\n",
      "Epoch 57/100\n",
      "56000/56000 [==============================] - 14s 248us/step - loss: 0.4070 - accuracy: 0.8526\n",
      "Epoch 58/100\n",
      "56000/56000 [==============================] - 14s 250us/step - loss: 0.4055 - accuracy: 0.8514s - loss: 0.4055 \n",
      "Epoch 59/100\n",
      "56000/56000 [==============================] - 14s 250us/step - loss: 0.4067 - accuracy: 0.8520\n",
      "Epoch 60/100\n",
      "56000/56000 [==============================] - 14s 256us/step - loss: 0.4048 - accuracy: 0.8522\n",
      "Epoch 61/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4069 - accuracy: 0.8510\n",
      "Epoch 62/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4069 - accuracy: 0.8511\n",
      "Epoch 63/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4059 - accuracy: 0.8515\n",
      "Epoch 64/100\n",
      "56000/56000 [==============================] - 14s 249us/step - loss: 0.4010 - accuracy: 0.8528\n",
      "Epoch 65/100\n",
      "56000/56000 [==============================] - 14s 251us/step - loss: 0.4040 - accuracy: 0.8520s - loss: 0.4033 - accuracy: \n",
      "Epoch 66/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4065 - accuracy: 0.8526\n",
      "Epoch 67/100\n",
      "56000/56000 [==============================] - 14s 253us/step - loss: 0.4031 - accuracy: 0.8525\n",
      "Epoch 68/100\n",
      "56000/56000 [==============================] - 14s 252us/step - loss: 0.4056 - accuracy: 0.8514s - loss: 0\n",
      "Epoch 69/100\n",
      "56000/56000 [==============================] - 14s 249us/step - loss: 0.4037 - accuracy: 0.8526\n",
      "Epoch 70/100\n",
      "56000/56000 [==============================] - 15s 271us/step - loss: 0.4044 - accuracy: 0.8517\n",
      "Epoch 71/100\n",
      "56000/56000 [==============================] - 15s 266us/step - loss: 0.4034 - accuracy: 0.8523\n",
      "Epoch 72/100\n",
      "56000/56000 [==============================] - 15s 267us/step - loss: 0.4041 - accuracy: 0.8529\n",
      "Epoch 73/100\n",
      "56000/56000 [==============================] - 15s 266us/step - loss: 0.4037 - accuracy: 0.8519\n",
      "Epoch 74/100\n",
      "56000/56000 [==============================] - 14s 259us/step - loss: 0.4039 - accuracy: 0.8521s - loss: 0.403\n",
      "Epoch 75/100\n",
      "56000/56000 [==============================] - 14s 259us/step - loss: 0.4018 - accuracy: 0.8535\n",
      "Epoch 76/100\n",
      "56000/56000 [==============================] - 14s 258us/step - loss: 0.4019 - accuracy: 0.8536\n",
      "Epoch 77/100\n",
      "56000/56000 [==============================] - 14s 258us/step - loss: 0.4022 - accuracy: 0.8528\n",
      "Epoch 78/100\n",
      "56000/56000 [==============================] - 14s 257us/step - loss: 0.4013 - accuracy: 0.8524\n",
      "Epoch 79/100\n",
      "56000/56000 [==============================] - 15s 262us/step - loss: 0.4015 - accuracy: 0.8525s - loss: 0.4019 - accuracy: \n",
      "Epoch 80/100\n",
      "56000/56000 [==============================] - 14s 257us/step - loss: 0.4006 - accuracy: 0.8542\n",
      "Epoch 81/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4026 - accuracy: 0.8525s - l - ETA: 0s - loss: 0.4030 - accura\n",
      "Epoch 82/100\n",
      "56000/56000 [==============================] - 14s 256us/step - loss: 0.4007 - accuracy: 0.8532\n",
      "Epoch 83/100\n",
      "56000/56000 [==============================] - 14s 257us/step - loss: 0.4035 - accuracy: 0.8531\n",
      "Epoch 84/100\n",
      "56000/56000 [==============================] - 15s 260us/step - loss: 0.3996 - accuracy: 0.8540\n",
      "Epoch 85/100\n",
      "56000/56000 [==============================] - 14s 254us/step - loss: 0.4025 - accuracy: 0.8526\n",
      "Epoch 86/100\n",
      "56000/56000 [==============================] - 14s 254us/step - loss: 0.4033 - accuracy: 0.8539s - l - E\n",
      "Epoch 87/100\n",
      "56000/56000 [==============================] - 14s 257us/step - loss: 0.4035 - accuracy: 0.8524\n",
      "Epoch 88/100\n",
      "56000/56000 [==============================] - 15s 260us/step - loss: 0.4036 - accuracy: 0.8541\n",
      "Epoch 89/100\n",
      "56000/56000 [==============================] - 14s 256us/step - loss: 0.4039 - accuracy: 0.8521\n",
      "Epoch 90/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4034 - accuracy: 0.8545\n",
      "Epoch 91/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4013 - accuracy: 0.8536\n",
      "Epoch 92/100\n",
      "56000/56000 [==============================] - 14s 258us/step - loss: 0.4027 - accuracy: 0.8539\n",
      "Epoch 93/100\n",
      "56000/56000 [==============================] - 14s 259us/step - loss: 0.4001 - accuracy: 0.8535\n",
      "Epoch 94/100\n",
      "56000/56000 [==============================] - 14s 253us/step - loss: 0.4021 - accuracy: 0.8540\n",
      "Epoch 95/100\n",
      "56000/56000 [==============================] - 14s 255us/step - loss: 0.4024 - accuracy: 0.8528\n",
      "Epoch 96/100\n",
      "56000/56000 [==============================] - 17s 303us/step - loss: 0.4029 - accuracy: 0.8539\n",
      "Epoch 97/100\n",
      "56000/56000 [==============================] - 17s 310us/step - loss: 0.4029 - accuracy: 0.8547\n",
      "Epoch 98/100\n",
      "56000/56000 [==============================] - 16s 288us/step - loss: 0.4027 - accuracy: 0.8523\n",
      "Epoch 99/100\n",
      "56000/56000 [==============================] - 14s 258us/step - loss: 0.3999 - accuracy: 0.8533\n",
      "Epoch 100/100\n",
      "56000/56000 [==============================] - 14s 257us/step - loss: 0.4028 - accuracy: 0.8541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e616c17d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising the Artificial Neural Network\n",
    "model = Sequential()\n",
    "#Creating the Input-layer and the first hidden layer\n",
    "model.add(Dense(300, input_dim=35, activation='sigmoid'))\n",
    "model.add(Dense(600, input_dim=35, activation='sigmoid'))\n",
    "model.add(Dense(600, input_dim=35, activation='sigmoid'))\n",
    "model.add(Dense(300, input_dim=35, activation='sigmoid'))\n",
    "#Creating the output  layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#Compiling the ANN classifier\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 2s 100us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4123147657414277, 0.8571666479110718]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "con = metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.3       , 0.35147745, 0.63175992, 0.89406237,\n",
       "       0.99063401, 1.        , 0.86736475, 0.3815261 ,        nan])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = np.diag(con) / (np.diag(con) +(con.sum(axis=0) - np.diag(con)))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29370629, 0.01485149, 0.13839559, 0.87037037, 0.8487429 ,\n",
       "       0.98495702, 0.9998673 , 0.66577361, 0.69343066, 0.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = np.diag(con)/ ((con.sum(axis=1) - np.diag(con)) + np.diag(con))\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40776699, 0.02830189, 0.19859402, 0.73211375, 0.8708134 ,\n",
       "       0.98778736, 0.99993365, 0.75331565, 0.49222798,        nan])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CorrelationAttributeEval\n",
    "features = ['id','ct_dst_sport_ltm','ct_dst_src_ltm','ct_src_dport_ltm','sttl','ct_srv_dst','ct_srv_src','ct_dst_ltm','ct_src_ltm','ct_state_ttl','state','swin','dwin','proto','service','rate','dttl','stcpb','dtcpb','dmean','dload','tcprtt','ackdat','synack']\n",
    "X2 = df[['id','ct_dst_sport_ltm','ct_dst_src_ltm','ct_src_dport_ltm','sttl','ct_srv_dst','ct_srv_src','ct_dst_ltm','ct_src_ltm','ct_state_ttl','state','swin','dwin','proto','service','rate','dttl','stcpb','dtcpb','dmean','dload','tcprtt','ackdat','synack']]\n",
    "Y2 = df[['attack_cat']]\n",
    "X3 = X2.iloc[:,0:24]  #independent columns\n",
    "Y3 = Y2.iloc[:,-1]    #target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sScaler = StandardScaler()\n",
    "rescaleX3 = sScaler.fit_transform(X3)\n",
    "df_rescaled = pd.DataFrame(data=rescaleX3, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rescaleX3, Y3, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56000/56000 [==============================] - 9s 159us/step - loss: 0.8981 - accuracy: 0.6719\n",
      "Epoch 2/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.7120 - accuracy: 0.7351\n",
      "Epoch 3/100\n",
      "56000/56000 [==============================] - 8s 143us/step - loss: 0.6689 - accuracy: 0.7490\n",
      "Epoch 4/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.6455 - accuracy: 0.7590\n",
      "Epoch 5/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.6303 - accuracy: 0.7660\n",
      "Epoch 6/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.6172 - accuracy: 0.7703\n",
      "Epoch 7/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.6091 - accuracy: 0.7739\n",
      "Epoch 8/100\n",
      "56000/56000 [==============================] - 8s 148us/step - loss: 0.6010 - accuracy: 0.7774\n",
      "Epoch 9/100\n",
      "56000/56000 [==============================] - 8s 148us/step - loss: 0.5951 - accuracy: 0.7802\n",
      "Epoch 10/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5870 - accuracy: 0.7826\n",
      "Epoch 11/100\n",
      "56000/56000 [==============================] - 8s 143us/step - loss: 0.5810 - accuracy: 0.7855\n",
      "Epoch 12/100\n",
      "56000/56000 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.78 - 8s 143us/step - loss: 0.5767 - accuracy: 0.7863\n",
      "Epoch 13/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5721 - accuracy: 0.7890\n",
      "Epoch 14/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5683 - accuracy: 0.7893\n",
      "Epoch 15/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.5670 - accuracy: 0.7909\n",
      "Epoch 16/100\n",
      "56000/56000 [==============================] - 8s 148us/step - loss: 0.5631 - accuracy: 0.7920\n",
      "Epoch 17/100\n",
      "56000/56000 [==============================] - 8s 149us/step - loss: 0.5604 - accuracy: 0.7922\n",
      "Epoch 18/100\n",
      "56000/56000 [==============================] - 8s 148us/step - loss: 0.5585 - accuracy: 0.7933\n",
      "Epoch 19/100\n",
      "56000/56000 [==============================] - 8s 147us/step - loss: 0.5559 - accuracy: 0.7939\n",
      "Epoch 20/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.5529 - accuracy: 0.7939\n",
      "Epoch 21/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5505 - accuracy: 0.7962\n",
      "Epoch 22/100\n",
      "56000/56000 [==============================] - 8s 147us/step - loss: 0.5499 - accuracy: 0.7956\n",
      "Epoch 23/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.5489 - accuracy: 0.7950\n",
      "Epoch 24/100\n",
      "56000/56000 [==============================] - 8s 147us/step - loss: 0.5471 - accuracy: 0.7961\n",
      "Epoch 25/100\n",
      "56000/56000 [==============================] - 8s 149us/step - loss: 0.5430 - accuracy: 0.7969\n",
      "Epoch 26/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5425 - accuracy: 0.7981\n",
      "Epoch 27/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5419 - accuracy: 0.7976\n",
      "Epoch 28/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5408 - accuracy: 0.7992\n",
      "Epoch 29/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5386 - accuracy: 0.7992\n",
      "Epoch 30/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.5380 - accuracy: 0.7996\n",
      "Epoch 31/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5381 - accuracy: 0.7999\n",
      "Epoch 32/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5356 - accuracy: 0.8005\n",
      "Epoch 33/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5363 - accuracy: 0.8002\n",
      "Epoch 34/100\n",
      "56000/56000 [==============================] - 8s 143us/step - loss: 0.5355 - accuracy: 0.7999\n",
      "Epoch 35/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5350 - accuracy: 0.8014\n",
      "Epoch 36/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.5341 - accuracy: 0.8019\n",
      "Epoch 37/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5341 - accuracy: 0.8008\n",
      "Epoch 38/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5335 - accuracy: 0.8012\n",
      "Epoch 39/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.5326 - accuracy: 0.8023\n",
      "Epoch 40/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5311 - accuracy: 0.8035\n",
      "Epoch 41/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5311 - accuracy: 0.8017\n",
      "Epoch 42/100\n",
      "56000/56000 [==============================] - 8s 149us/step - loss: 0.5287 - accuracy: 0.8030\n",
      "Epoch 43/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5306 - accuracy: 0.8025\n",
      "Epoch 44/100\n",
      "56000/56000 [==============================] - 8s 143us/step - loss: 0.5301 - accuracy: 0.8034\n",
      "Epoch 45/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.5305 - accuracy: 0.8037\n",
      "Epoch 46/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5290 - accuracy: 0.8043\n",
      "Epoch 47/100\n",
      "56000/56000 [==============================] - 8s 143us/step - loss: 0.5285 - accuracy: 0.8042\n",
      "Epoch 48/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5302 - accuracy: 0.8034\n",
      "Epoch 49/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5273 - accuracy: 0.8032\n",
      "Epoch 50/100\n",
      "56000/56000 [==============================] - 8s 147us/step - loss: 0.5282 - accuracy: 0.8040\n",
      "Epoch 51/100\n",
      "56000/56000 [==============================] - 8s 143us/step - loss: 0.5282 - accuracy: 0.8046\n",
      "Epoch 52/100\n",
      "56000/56000 [==============================] - 8s 142us/step - loss: 0.5279 - accuracy: 0.8051\n",
      "Epoch 53/100\n",
      "56000/56000 [==============================] - 8s 143us/step - loss: 0.5289 - accuracy: 0.8038\n",
      "Epoch 54/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.5270 - accuracy: 0.8046\n",
      "Epoch 55/100\n",
      "56000/56000 [==============================] - 8s 142us/step - loss: 0.5265 - accuracy: 0.8046\n",
      "Epoch 56/100\n",
      "56000/56000 [==============================] - 8s 142us/step - loss: 0.5262 - accuracy: 0.8036\n",
      "Epoch 57/100\n",
      "56000/56000 [==============================] - 8s 144us/step - loss: 0.5273 - accuracy: 0.8039\n",
      "Epoch 58/100\n",
      "56000/56000 [==============================] - 8s 147us/step - loss: 0.5254 - accuracy: 0.8051\n",
      "Epoch 59/100\n",
      "56000/56000 [==============================] - 8s 145us/step - loss: 0.5259 - accuracy: 0.8048\n",
      "Epoch 60/100\n",
      "56000/56000 [==============================] - 10s 172us/step - loss: 0.5262 - accuracy: 0.8043\n",
      "Epoch 61/100\n",
      "56000/56000 [==============================] - 10s 172us/step - loss: 0.5246 - accuracy: 0.8054\n",
      "Epoch 62/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.5251 - accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5251 - accuracy: 0.8061\n",
      "Epoch 64/100\n",
      "56000/56000 [==============================] - 9s 165us/step - loss: 0.5277 - accuracy: 0.8054\n",
      "Epoch 65/100\n",
      "56000/56000 [==============================] - 10s 170us/step - loss: 0.5258 - accuracy: 0.8057\n",
      "Epoch 66/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5248 - accuracy: 0.8051\n",
      "Epoch 67/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.5241 - accuracy: 0.8050\n",
      "Epoch 68/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.5259 - accuracy: 0.8062\n",
      "Epoch 69/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5252 - accuracy: 0.8048\n",
      "Epoch 70/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.5243 - accuracy: 0.8057\n",
      "Epoch 71/100\n",
      "56000/56000 [==============================] - 9s 165us/step - loss: 0.5247 - accuracy: 0.8066\n",
      "Epoch 72/100\n",
      "56000/56000 [==============================] - 9s 167us/step - loss: 0.5231 - accuracy: 0.8068\n",
      "Epoch 73/100\n",
      "56000/56000 [==============================] - 9s 166us/step - loss: 0.5259 - accuracy: 0.8050\n",
      "Epoch 74/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5233 - accuracy: 0.8058\n",
      "Epoch 75/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5241 - accuracy: 0.8058\n",
      "Epoch 76/100\n",
      "56000/56000 [==============================] - 9s 167us/step - loss: 0.5255 - accuracy: 0.8056\n",
      "Epoch 77/100\n",
      "56000/56000 [==============================] - 9s 159us/step - loss: 0.5234 - accuracy: 0.8056\n",
      "Epoch 78/100\n",
      "56000/56000 [==============================] - 9s 161us/step - loss: 0.5247 - accuracy: 0.8060\n",
      "Epoch 79/100\n",
      "56000/56000 [==============================] - 9s 160us/step - loss: 0.5248 - accuracy: 0.8055\n",
      "Epoch 80/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5250 - accuracy: 0.8064\n",
      "Epoch 81/100\n",
      "56000/56000 [==============================] - 9s 158us/step - loss: 0.5248 - accuracy: 0.8059\n",
      "Epoch 82/100\n",
      "56000/56000 [==============================] - 9s 157us/step - loss: 0.5237 - accuracy: 0.8064\n",
      "Epoch 83/100\n",
      "56000/56000 [==============================] - 9s 158us/step - loss: 0.5264 - accuracy: 0.8070\n",
      "Epoch 84/100\n",
      "56000/56000 [==============================] - 9s 156us/step - loss: 0.5260 - accuracy: 0.8058\n",
      "Epoch 85/100\n",
      "56000/56000 [==============================] - 9s 156us/step - loss: 0.5251 - accuracy: 0.8061\n",
      "Epoch 86/100\n",
      "56000/56000 [==============================] - 9s 158us/step - loss: 0.5249 - accuracy: 0.8073\n",
      "Epoch 87/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5243 - accuracy: 0.8064\n",
      "Epoch 88/100\n",
      "56000/56000 [==============================] - 9s 167us/step - loss: 0.5249 - accuracy: 0.8077\n",
      "Epoch 89/100\n",
      "56000/56000 [==============================] - 9s 160us/step - loss: 0.5245 - accuracy: 0.8078\n",
      "Epoch 90/100\n",
      "56000/56000 [==============================] - 9s 160us/step - loss: 0.5254 - accuracy: 0.8055\n",
      "Epoch 91/100\n",
      "56000/56000 [==============================] - 9s 161us/step - loss: 0.5258 - accuracy: 0.8066\n",
      "Epoch 92/100\n",
      "56000/56000 [==============================] - 9s 161us/step - loss: 0.5258 - accuracy: 0.8067\n",
      "Epoch 93/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5247 - accuracy: 0.8058\n",
      "Epoch 94/100\n",
      "56000/56000 [==============================] - 9s 166us/step - loss: 0.5233 - accuracy: 0.8072\n",
      "Epoch 95/100\n",
      "56000/56000 [==============================] - 9s 161us/step - loss: 0.5267 - accuracy: 0.8056\n",
      "Epoch 96/100\n",
      "56000/56000 [==============================] - 9s 167us/step - loss: 0.5247 - accuracy: 0.8057\n",
      "Epoch 97/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5255 - accuracy: 0.8051\n",
      "Epoch 98/100\n",
      "56000/56000 [==============================] - 10s 170us/step - loss: 0.5255 - accuracy: 0.8060\n",
      "Epoch 99/100\n",
      "56000/56000 [==============================] - 9s 168us/step - loss: 0.5244 - accuracy: 0.8063\n",
      "Epoch 100/100\n",
      "56000/56000 [==============================] - 9s 166us/step - loss: 0.5256 - accuracy: 0.8069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e6169734a8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising the Artificial Neural Network\n",
    "model = Sequential()\n",
    "#Creating the Input-layer and the first hidden layer\n",
    "model.add(Dense(200, input_dim=24, activation='sigmoid'))\n",
    "model.add(Dense(400, input_dim=24, activation='sigmoid'))\n",
    "model.add(Dense(400, input_dim=24, activation='sigmoid'))\n",
    "model.add(Dense(200, input_dim=24, activation='sigmoid'))\n",
    "#Creating the output  layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#Compiling the ANN classifier\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 2s 80us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5547136311531067, 0.8036249876022339]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "predictions = model.predict(X_test)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "con = metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59090909, 0.23423423, 0.37115215, 0.61489362, 0.73997413,\n",
       "       0.99872123, 0.98104265, 0.51195586,        nan,        nan])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = np.diag(con) / (np.diag(con) +(con.sum(axis=0) - np.diag(con)))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09848485, 0.11016949, 0.24563446, 0.82012661, 0.69983687,\n",
       "       0.97869674, 0.92972259, 0.57986111, 0.        , 0.        ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = np.diag(con)/ ((con.sum(axis=1) - np.diag(con)) + np.diag(con))\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16883117, 0.14985591, 0.29562172, 0.70283416, 0.71934605,\n",
       "       0.98860759, 0.95469343, 0.54379681,        nan,        nan])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PrincipalComponentAnalysis\n",
    "features = ['id','dur','dwin','proto','djit','swin','smean','state','service','ct_src_dport_ltm','ct_dst_ltm','ct_dst_sport_ltm','ct_src_ltm','ct_flw_http_mthd','ct_srv_dst','dpkts','dloss','dbytes','sttl','dmean','spkts','sbytes','sloss','sinpkt','label']\n",
    "X2 = df[['id','dur','dwin','proto','djit','swin','smean','state','service','ct_src_dport_ltm','ct_dst_ltm','ct_dst_sport_ltm','ct_src_ltm','ct_flw_http_mthd','ct_srv_dst','dpkts','dloss','dbytes','sttl','dmean','spkts','sbytes','sloss','sinpkt','label']]\n",
    "Y2 = df[['attack_cat']]\n",
    "X3 = X2.iloc[:,0:25]  #independent columns\n",
    "Y3 = Y2.iloc[:,-1]    #target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sScaler = StandardScaler()\n",
    "rescaleX3 = sScaler.fit_transform(X3)\n",
    "df_rescaled = pd.DataFrame(data=rescaleX3, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rescaleX3, Y3, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56000/56000 [==============================] - 10s 175us/step - loss: 0.7400 - accuracy: 0.7329\n",
      "Epoch 2/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.5890 - accuracy: 0.7834\n",
      "Epoch 3/100\n",
      "56000/56000 [==============================] - 9s 166us/step - loss: 0.5575 - accuracy: 0.7864\n",
      "Epoch 4/100\n",
      "56000/56000 [==============================] - 9s 166us/step - loss: 0.5341 - accuracy: 0.7941\n",
      "Epoch 5/100\n",
      "56000/56000 [==============================] - 9s 162us/step - loss: 0.5139 - accuracy: 0.8056\n",
      "Epoch 6/100\n",
      "56000/56000 [==============================] - 9s 162us/step - loss: 0.4968 - accuracy: 0.8151\n",
      "Epoch 7/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4787 - accuracy: 0.8247\n",
      "Epoch 8/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4672 - accuracy: 0.8302\n",
      "Epoch 9/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4567 - accuracy: 0.8332\n",
      "Epoch 10/100\n",
      "56000/56000 [==============================] - 9s 167us/step - loss: 0.4488 - accuracy: 0.8362\n",
      "Epoch 11/100\n",
      "56000/56000 [==============================] - 9s 169us/step - loss: 0.4440 - accuracy: 0.8364\n",
      "Epoch 12/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4367 - accuracy: 0.8389\n",
      "Epoch 13/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4328 - accuracy: 0.8402\n",
      "Epoch 14/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.4298 - accuracy: 0.8421\n",
      "Epoch 15/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.4277 - accuracy: 0.8429\n",
      "Epoch 16/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4247 - accuracy: 0.8434\n",
      "Epoch 17/100\n",
      "56000/56000 [==============================] - 9s 166us/step - loss: 0.4241 - accuracy: 0.8433\n",
      "Epoch 18/100\n",
      "56000/56000 [==============================] - 9s 168us/step - loss: 0.4235 - accuracy: 0.8438\n",
      "Epoch 19/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4205 - accuracy: 0.8443\n",
      "Epoch 20/100\n",
      "56000/56000 [==============================] - 9s 162us/step - loss: 0.4193 - accuracy: 0.8438\n",
      "Epoch 21/100\n",
      "56000/56000 [==============================] - ETA: 0s - loss: 0.4201 - accuracy: 0.84 - 9s 163us/step - loss: 0.4199 - accuracy: 0.8441\n",
      "Epoch 22/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4193 - accuracy: 0.8451\n",
      "Epoch 23/100\n",
      "56000/56000 [==============================] - 9s 165us/step - loss: 0.4176 - accuracy: 0.8446\n",
      "Epoch 24/100\n",
      "56000/56000 [==============================] - 9s 168us/step - loss: 0.4177 - accuracy: 0.8459\n",
      "Epoch 25/100\n",
      "56000/56000 [==============================] - 10s 187us/step - loss: 0.4166 - accuracy: 0.8445\n",
      "Epoch 26/100\n",
      "56000/56000 [==============================] - 10s 185us/step - loss: 0.4174 - accuracy: 0.8451\n",
      "Epoch 27/100\n",
      "56000/56000 [==============================] - 10s 184us/step - loss: 0.4159 - accuracy: 0.8468\n",
      "Epoch 28/100\n",
      "56000/56000 [==============================] - 10s 183us/step - loss: 0.4166 - accuracy: 0.8476\n",
      "Epoch 29/100\n",
      "56000/56000 [==============================] - 10s 184us/step - loss: 0.4167 - accuracy: 0.8471\n",
      "Epoch 30/100\n",
      "56000/56000 [==============================] - 10s 186us/step - loss: 0.4163 - accuracy: 0.8474\n",
      "Epoch 31/100\n",
      "56000/56000 [==============================] - 11s 191us/step - loss: 0.4146 - accuracy: 0.8475\n",
      "Epoch 32/100\n",
      "56000/56000 [==============================] - 10s 185us/step - loss: 0.4146 - accuracy: 0.8461\n",
      "Epoch 33/100\n",
      "56000/56000 [==============================] - 10s 180us/step - loss: 0.4140 - accuracy: 0.8483\n",
      "Epoch 34/100\n",
      "56000/56000 [==============================] - 9s 165us/step - loss: 0.4131 - accuracy: 0.8467\n",
      "Epoch 35/100\n",
      "56000/56000 [==============================] - 9s 167us/step - loss: 0.4130 - accuracy: 0.8478\n",
      "Epoch 36/100\n",
      "56000/56000 [==============================] - 9s 165us/step - loss: 0.4120 - accuracy: 0.8478\n",
      "Epoch 37/100\n",
      "56000/56000 [==============================] - 10s 172us/step - loss: 0.4124 - accuracy: 0.8486\n",
      "Epoch 38/100\n",
      "56000/56000 [==============================] - 11s 190us/step - loss: 0.4112 - accuracy: 0.8479\n",
      "Epoch 39/100\n",
      "56000/56000 [==============================] - 9s 165us/step - loss: 0.4110 - accuracy: 0.8496\n",
      "Epoch 40/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4095 - accuracy: 0.8494\n",
      "Epoch 41/100\n",
      "56000/56000 [==============================] - 9s 159us/step - loss: 0.4099 - accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "56000/56000 [==============================] - 11s 195us/step - loss: 0.4084 - accuracy: 0.8485\n",
      "Epoch 43/100\n",
      "56000/56000 [==============================] - 13s 225us/step - loss: 0.4096 - accuracy: 0.8484\n",
      "Epoch 44/100\n",
      "56000/56000 [==============================] - 11s 199us/step - loss: 0.4074 - accuracy: 0.8492\n",
      "Epoch 45/100\n",
      "56000/56000 [==============================] - 11s 200us/step - loss: 0.4070 - accuracy: 0.8502\n",
      "Epoch 46/100\n",
      "56000/56000 [==============================] - 10s 181us/step - loss: 0.4067 - accuracy: 0.8495\n",
      "Epoch 47/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.4074 - accuracy: 0.8493\n",
      "Epoch 48/100\n",
      "56000/56000 [==============================] - 9s 167us/step - loss: 0.4068 - accuracy: 0.8491\n",
      "Epoch 49/100\n",
      "56000/56000 [==============================] - 10s 176us/step - loss: 0.4063 - accuracy: 0.8496\n",
      "Epoch 50/100\n",
      "56000/56000 [==============================] - 10s 176us/step - loss: 0.4070 - accuracy: 0.8500s - loss: 0.405\n",
      "Epoch 51/100\n",
      "56000/56000 [==============================] - 9s 166us/step - loss: 0.4059 - accuracy: 0.8504\n",
      "Epoch 52/100\n",
      "56000/56000 [==============================] - 10s 170us/step - loss: 0.4050 - accuracy: 0.8500\n",
      "Epoch 53/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.4046 - accuracy: 0.8501\n",
      "Epoch 54/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.4062 - accuracy: 0.8503\n",
      "Epoch 55/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.4042 - accuracy: 0.8500\n",
      "Epoch 56/100\n",
      "56000/56000 [==============================] - 8s 149us/step - loss: 0.4034 - accuracy: 0.8507\n",
      "Epoch 57/100\n",
      "56000/56000 [==============================] - 8s 146us/step - loss: 0.4034 - accuracy: 0.8502\n",
      "Epoch 58/100\n",
      "56000/56000 [==============================] - 8s 149us/step - loss: 0.4042 - accuracy: 0.8511\n",
      "Epoch 59/100\n",
      "56000/56000 [==============================] - 8s 151us/step - loss: 0.4039 - accuracy: 0.8514\n",
      "Epoch 60/100\n",
      "56000/56000 [==============================] - 8s 149us/step - loss: 0.4025 - accuracy: 0.8511\n",
      "Epoch 61/100\n",
      "56000/56000 [==============================] - 9s 159us/step - loss: 0.4037 - accuracy: 0.8524\n",
      "Epoch 62/100\n",
      "56000/56000 [==============================] - 9s 163us/step - loss: 0.4053 - accuracy: 0.8504\n",
      "Epoch 63/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.4035 - accuracy: 0.8513\n",
      "Epoch 64/100\n",
      "56000/56000 [==============================] - 9s 161us/step - loss: 0.4042 - accuracy: 0.8506\n",
      "Epoch 65/100\n",
      "56000/56000 [==============================] - 9s 168us/step - loss: 0.4035 - accuracy: 0.85080s\n",
      "Epoch 66/100\n",
      "56000/56000 [==============================] - 9s 164us/step - loss: 0.4047 - accuracy: 0.8500\n",
      "Epoch 67/100\n",
      "56000/56000 [==============================] - 9s 156us/step - loss: 0.4023 - accuracy: 0.8524\n",
      "Epoch 68/100\n",
      "56000/56000 [==============================] - 9s 154us/step - loss: 0.4023 - accuracy: 0.8508\n",
      "Epoch 69/100\n",
      "56000/56000 [==============================] - 9s 156us/step - loss: 0.4036 - accuracy: 0.8506\n",
      "Epoch 70/100\n",
      "56000/56000 [==============================] - 9s 158us/step - loss: 0.4028 - accuracy: 0.8522\n",
      "Epoch 71/100\n",
      "56000/56000 [==============================] - 9s 154us/step - loss: 0.4023 - accuracy: 0.8511\n",
      "Epoch 72/100\n",
      "56000/56000 [==============================] - 10s 173us/step - loss: 0.4037 - accuracy: 0.8508\n",
      "Epoch 73/100\n",
      "56000/56000 [==============================] - 11s 201us/step - loss: 0.4025 - accuracy: 0.8505\n",
      "Epoch 74/100\n",
      "56000/56000 [==============================] - 9s 161us/step - loss: 0.4014 - accuracy: 0.8522\n",
      "Epoch 75/100\n",
      "56000/56000 [==============================] - 9s 161us/step - loss: 0.4018 - accuracy: 0.8518\n",
      "Epoch 76/100\n",
      "56000/56000 [==============================] - 9s 161us/step - loss: 0.4000 - accuracy: 0.8522\n",
      "Epoch 77/100\n",
      "56000/56000 [==============================] - 9s 160us/step - loss: 0.4020 - accuracy: 0.8521\n",
      "Epoch 78/100\n",
      "56000/56000 [==============================] - 10s 172us/step - loss: 0.3997 - accuracy: 0.8526\n",
      "Epoch 79/100\n",
      "56000/56000 [==============================] - 127s 2ms/step - loss: 0.4023 - accuracy: 0.8524\n",
      "Epoch 80/100\n",
      "56000/56000 [==============================] - 8s 143us/step - loss: 0.4013 - accuracy: 0.8510\n",
      "Epoch 81/100\n",
      "56000/56000 [==============================] - 6s 103us/step - loss: 0.4036 - accuracy: 0.8517\n",
      "Epoch 82/100\n",
      "56000/56000 [==============================] - 7s 123us/step - loss: 0.4006 - accuracy: 0.8524\n",
      "Epoch 83/100\n",
      "56000/56000 [==============================] - 6s 103us/step - loss: 0.4009 - accuracy: 0.8532\n",
      "Epoch 84/100\n",
      "56000/56000 [==============================] - 5s 94us/step - loss: 0.4003 - accuracy: 0.8518\n",
      "Epoch 85/100\n",
      "56000/56000 [==============================] - 5s 93us/step - loss: 0.4017 - accuracy: 0.8512\n",
      "Epoch 86/100\n",
      "56000/56000 [==============================] - 5s 92us/step - loss: 0.4009 - accuracy: 0.8525\n",
      "Epoch 87/100\n",
      "56000/56000 [==============================] - 5s 92us/step - loss: 0.4024 - accuracy: 0.8528\n",
      "Epoch 88/100\n",
      "56000/56000 [==============================] - 5s 94us/step - loss: 0.4006 - accuracy: 0.8516\n",
      "Epoch 89/100\n",
      "56000/56000 [==============================] - 5s 93us/step - loss: 0.4014 - accuracy: 0.8512\n",
      "Epoch 90/100\n",
      "56000/56000 [==============================] - 6s 99us/step - loss: 0.4015 - accuracy: 0.8527\n",
      "Epoch 91/100\n",
      "56000/56000 [==============================] - 5s 97us/step - loss: 0.3993 - accuracy: 0.8516\n",
      "Epoch 92/100\n",
      "56000/56000 [==============================] - 5s 94us/step - loss: 0.3994 - accuracy: 0.8519\n",
      "Epoch 93/100\n",
      "56000/56000 [==============================] - 5s 93us/step - loss: 0.3989 - accuracy: 0.8516\n",
      "Epoch 94/100\n",
      "56000/56000 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 0.85 - 5s 93us/step - loss: 0.4012 - accuracy: 0.8514\n",
      "Epoch 95/100\n",
      "56000/56000 [==============================] - 5s 95us/step - loss: 0.3985 - accuracy: 0.8526\n",
      "Epoch 96/100\n",
      "56000/56000 [==============================] - 5s 93us/step - loss: 0.3991 - accuracy: 0.8510\n",
      "Epoch 97/100\n",
      "56000/56000 [==============================] - 5s 92us/step - loss: 0.4001 - accuracy: 0.8522\n",
      "Epoch 98/100\n",
      "56000/56000 [==============================] - 5s 94us/step - loss: 0.3972 - accuracy: 0.8528\n",
      "Epoch 99/100\n",
      "56000/56000 [==============================] - 5s 93us/step - loss: 0.3988 - accuracy: 0.8528\n",
      "Epoch 100/100\n",
      "56000/56000 [==============================] - 5s 93us/step - loss: 0.3974 - accuracy: 0.8528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e61b0f1e10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising the Artificial Neural Network\n",
    "model = Sequential()\n",
    "#Creating the Input-layer and the first hidden layer\n",
    "model.add(Dense(200, input_dim=25, activation='sigmoid'))\n",
    "model.add(Dense(400, input_dim=25, activation='sigmoid'))\n",
    "model.add(Dense(400, input_dim=25, activation='sigmoid'))\n",
    "model.add(Dense(200, input_dim=25, activation='sigmoid'))\n",
    "#Creating the output  layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#Compiling the ANN classifier\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56000/56000 [==============================] - 2s 37us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3890355060015406, 0.852446436882019]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 1s 32us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40761351148287456, 0.8500833511352539]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "con = metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.57342657, 0.39285714, 0.37982973, 0.67854376, 0.8202765 ,\n",
       "       0.98191355, 1.        , 0.76688938, 0.53731343,        nan])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = np.diag(con) / (np.diag(con) +(con.sum(axis=0) - np.diag(con)))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29078014, 0.05288462, 0.3427896 , 0.7550097 , 0.8700611 ,\n",
       "       0.9842277 , 0.9997366 , 0.70319946, 0.27906977, 0.        ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = np.diag(con)/ ((con.sum(axis=1) - np.diag(con)) + np.diag(con))\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38588235, 0.09322034, 0.36036036, 0.71473738, 0.84443566,\n",
       "       0.98306926, 0.99986828, 0.73366477, 0.36734694,        nan])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_minority0 = df[df.attack_cat==0]\n",
    "df_minority1 = df[df.attack_cat==1]\n",
    "df_minority2 = df[df.attack_cat==2]\n",
    "df_minority3 = df[df.attack_cat==3]\n",
    "df_minority7 = df[df.attack_cat==7]\n",
    "df_minority8 = df[df.attack_cat==8]\n",
    "df_minority9 = df[df.attack_cat==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled0 = resample(df_minority0, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=5000)    # to match majority class\n",
    "df_minority_upsampled1 = resample(df_minority1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=5000)    # to match majority class\n",
    "df_minority_upsampled2 = resample(df_minority2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=6000)    # to match majority class\n",
    "df_minority_upsampled3 = resample(df_minority3, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=6000)    # to match majority class\n",
    "df_minority_upsampled7 = resample(df_minority7, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=3000)    # to match majority class\n",
    "df_minority_upsampled8 = resample(df_minority8, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=5000)\n",
    "df_minority_upsampled9 = resample(df_minority9, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=6000)    # to match majority class\n",
    "df = pd.concat([df, df_minority_upsampled0, df_minority_upsampled1, df_minority_upsampled2, df_minority_upsampled3, df_minority_upsampled7, df_minority_upsampled8, df_minority_upsampled9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info Gain Attribute Eval(CA)\n",
    "features = ['sttl','ct_state_ttl','ct_flw_http_mthd','sbytes','id','smean','sload','dur','sinpkt','rate','proto','ct_dst_src_ltm','service','dbytes','sjit','ct_srv_dst','dload','dinpkt','dmean','ct_srv_src','synack','tcprtt','ct_dst_sport_ltm','djit','ct_src_dport_ltm','dtcpb','stcpb','spkts','dloss','ct_dst_ltm','ackdat','label','dpkts','ct_src_ltm','sloss']\n",
    "X2 = df[['sttl','ct_state_ttl','ct_flw_http_mthd','sbytes','id','smean','sload','dur','sinpkt','rate','proto','ct_dst_src_ltm','service','dbytes','sjit','ct_srv_dst','dload','dinpkt','dmean','ct_srv_src','synack','tcprtt','ct_dst_sport_ltm','djit','ct_src_dport_ltm','dtcpb','stcpb','spkts','dloss','ct_dst_ltm','ackdat','label','dpkts','ct_src_ltm','sloss']]\n",
    "Y2 = df[['attack_cat']]\n",
    "X3 = X2.iloc[:,0:35]  #independent columns\n",
    "Y3 = Y2.iloc[:,-1]    #target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sScaler = StandardScaler()\n",
    "rescaleX3 = sScaler.fit_transform(X3)\n",
    "df_rescaled = pd.DataFrame(data=rescaleX3, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rescaleX3, Y3, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "81200/81200 [==============================] - 20s 245us/step - loss: 1.0653 - accuracy: 0.5957\n",
      "Epoch 2/100\n",
      "81200/81200 [==============================] - 18s 227us/step - loss: 0.8234 - accuracy: 0.6733\n",
      "Epoch 3/100\n",
      "81200/81200 [==============================] - 19s 230us/step - loss: 0.7418 - accuracy: 0.7045\n",
      "Epoch 4/100\n",
      "81200/81200 [==============================] - 18s 227us/step - loss: 0.7053 - accuracy: 0.7185s -\n",
      "Epoch 5/100\n",
      "81200/81200 [==============================] - 19s 233us/step - loss: 0.6846 - accuracy: 0.7267\n",
      "Epoch 6/100\n",
      "81200/81200 [==============================] - 18s 225us/step - loss: 0.6709 - accuracy: 0.7306\n",
      "Epoch 7/100\n",
      "81200/81200 [==============================] - 18s 225us/step - loss: 0.6606 - accuracy: 0.7358\n",
      "Epoch 8/100\n",
      "81200/81200 [==============================] - 18s 219us/step - loss: 0.6508 - accuracy: 0.7400\n",
      "Epoch 9/100\n",
      "81200/81200 [==============================] - 18s 219us/step - loss: 0.6425 - accuracy: 0.7431\n",
      "Epoch 10/100\n",
      "81200/81200 [==============================] - 18s 220us/step - loss: 0.6345 - accuracy: 0.7478\n",
      "Epoch 11/100\n",
      "81200/81200 [==============================] - 18s 223us/step - loss: 0.6275 - accuracy: 0.7509\n",
      "Epoch 12/100\n",
      "81200/81200 [==============================] - 18s 222us/step - loss: 0.6224 - accuracy: 0.7527\n",
      "Epoch 13/100\n",
      "81200/81200 [==============================] - 18s 221us/step - loss: 0.6162 - accuracy: 0.7560\n",
      "Epoch 14/100\n",
      "81200/81200 [==============================] - 18s 223us/step - loss: 0.6119 - accuracy: 0.7582\n",
      "Epoch 15/100\n",
      "81200/81200 [==============================] - 19s 230us/step - loss: 0.6063 - accuracy: 0.7609\n",
      "Epoch 16/100\n",
      "81200/81200 [==============================] - 21s 256us/step - loss: 0.6014 - accuracy: 0.7616\n",
      "Epoch 17/100\n",
      "81200/81200 [==============================] - 21s 257us/step - loss: 0.5979 - accuracy: 0.7629\n",
      "Epoch 18/100\n",
      "81200/81200 [==============================] - 23s 282us/step - loss: 0.5942 - accuracy: 0.7661\n",
      "Epoch 19/100\n",
      "81200/81200 [==============================] - 23s 279us/step - loss: 0.5901 - accuracy: 0.7667\n",
      "Epoch 20/100\n",
      "81200/81200 [==============================] - 21s 257us/step - loss: 0.5870 - accuracy: 0.7681\n",
      "Epoch 21/100\n",
      "81200/81200 [==============================] - 18s 221us/step - loss: 0.5861 - accuracy: 0.7686\n",
      "Epoch 22/100\n",
      "81200/81200 [==============================] - 21s 263us/step - loss: 0.5829 - accuracy: 0.7685\n",
      "Epoch 23/100\n",
      "81200/81200 [==============================] - 22s 276us/step - loss: 0.5796 - accuracy: 0.7714\n",
      "Epoch 24/100\n",
      "81200/81200 [==============================] - 22s 276us/step - loss: 0.5788 - accuracy: 0.7725s - loss: 0.5791 - accu\n",
      "Epoch 25/100\n",
      "81200/81200 [==============================] - 22s 266us/step - loss: 0.5759 - accuracy: 0.7730\n",
      "Epoch 26/100\n",
      "81200/81200 [==============================] - 20s 252us/step - loss: 0.5739 - accuracy: 0.7746\n",
      "Epoch 27/100\n",
      "81200/81200 [==============================] - 20s 247us/step - loss: 0.5714 - accuracy: 0.7750\n",
      "Epoch 28/100\n",
      "81200/81200 [==============================] - 20s 249us/step - loss: 0.5700 - accuracy: 0.7758\n",
      "Epoch 29/100\n",
      "81200/81200 [==============================] - 20s 252us/step - loss: 0.5708 - accuracy: 0.7759\n",
      "Epoch 30/100\n",
      "81200/81200 [==============================] - 21s 260us/step - loss: 0.5674 - accuracy: 0.7764\n",
      "Epoch 31/100\n",
      "81200/81200 [==============================] - 20s 246us/step - loss: 0.5655 - accuracy: 0.7765\n",
      "Epoch 32/100\n",
      "81200/81200 [==============================] - 18s 225us/step - loss: 0.5664 - accuracy: 0.7777\n",
      "Epoch 33/100\n",
      "81200/81200 [==============================] - 20s 248us/step - loss: 0.5637 - accuracy: 0.7784\n",
      "Epoch 34/100\n",
      "81200/81200 [==============================] - 21s 254us/step - loss: 0.5647 - accuracy: 0.7773\n",
      "Epoch 35/100\n",
      "81200/81200 [==============================] - 21s 254us/step - loss: 0.5623 - accuracy: 0.7782\n",
      "Epoch 36/100\n",
      "81200/81200 [==============================] - 20s 250us/step - loss: 0.5607 - accuracy: 0.7784\n",
      "Epoch 37/100\n",
      "81200/81200 [==============================] - 20s 249us/step - loss: 0.5603 - accuracy: 0.7804\n",
      "Epoch 38/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5600 - accuracy: 0.7789\n",
      "Epoch 39/100\n",
      "81200/81200 [==============================] - 20s 249us/step - loss: 0.5581 - accuracy: 0.7800\n",
      "Epoch 40/100\n",
      "81200/81200 [==============================] - 18s 227us/step - loss: 0.5585 - accuracy: 0.7803\n",
      "Epoch 41/100\n",
      "81200/81200 [==============================] - 21s 258us/step - loss: 0.5565 - accuracy: 0.7811\n",
      "Epoch 42/100\n",
      "81200/81200 [==============================] - 20s 251us/step - loss: 0.5570 - accuracy: 0.7802\n",
      "Epoch 43/100\n",
      "81200/81200 [==============================] - 20s 247us/step - loss: 0.5547 - accuracy: 0.7820\n",
      "Epoch 44/100\n",
      "81200/81200 [==============================] - 20s 247us/step - loss: 0.5541 - accuracy: 0.7811\n",
      "Epoch 45/100\n",
      "81200/81200 [==============================] - 21s 258us/step - loss: 0.5537 - accuracy: 0.7820\n",
      "Epoch 46/100\n",
      "81200/81200 [==============================] - 20s 251us/step - loss: 0.5546 - accuracy: 0.7809\n",
      "Epoch 47/100\n",
      "81200/81200 [==============================] - 20s 250us/step - loss: 0.5543 - accuracy: 0.7821s - loss: 0.5547 - accuracy: 0.78\n",
      "Epoch 48/100\n",
      "81200/81200 [==============================] - 21s 256us/step - loss: 0.5534 - accuracy: 0.7829\n",
      "Epoch 49/100\n",
      "81200/81200 [==============================] - 21s 256us/step - loss: 0.5534 - accuracy: 0.7816\n",
      "Epoch 50/100\n",
      "81200/81200 [==============================] - 20s 248us/step - loss: 0.5535 - accuracy: 0.7837\n",
      "Epoch 51/100\n",
      "81200/81200 [==============================] - 21s 257us/step - loss: 0.5546 - accuracy: 0.7829\n",
      "Epoch 52/100\n",
      "81200/81200 [==============================] - 21s 255us/step - loss: 0.5522 - accuracy: 0.7847\n",
      "Epoch 53/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5539 - accuracy: 0.7826\n",
      "Epoch 54/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5534 - accuracy: 0.7832\n",
      "Epoch 55/100\n",
      "81200/81200 [==============================] - 21s 254us/step - loss: 0.5540 - accuracy: 0.7818\n",
      "Epoch 56/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5564 - accuracy: 0.7829\n",
      "Epoch 57/100\n",
      "81200/81200 [==============================] - 20s 249us/step - loss: 0.5530 - accuracy: 0.7828\n",
      "Epoch 58/100\n",
      "81200/81200 [==============================] - 18s 226us/step - loss: 0.5539 - accuracy: 0.7842s - loss: 0.553 - ETA: 1s - loss:\n",
      "Epoch 59/100\n",
      "81200/81200 [==============================] - 19s 232us/step - loss: 0.5557 - accuracy: 0.7836\n",
      "Epoch 60/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5553 - accuracy: 0.7837\n",
      "Epoch 61/100\n",
      "81200/81200 [==============================] - 21s 260us/step - loss: 0.5540 - accuracy: 0.7833\n",
      "Epoch 62/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5529 - accuracy: 0.7828\n",
      "Epoch 63/100\n",
      "81200/81200 [==============================] - 20s 252us/step - loss: 0.5559 - accuracy: 0.7833\n",
      "Epoch 64/100\n",
      "81200/81200 [==============================] - 21s 259us/step - loss: 0.5557 - accuracy: 0.7837\n",
      "Epoch 65/100\n",
      "81200/81200 [==============================] - 20s 251us/step - loss: 0.5577 - accuracy: 0.7836\n",
      "Epoch 66/100\n",
      "81200/81200 [==============================] - 21s 254us/step - loss: 0.5548 - accuracy: 0.7821\n",
      "Epoch 67/100\n",
      "81200/81200 [==============================] - 21s 264us/step - loss: 0.5595 - accuracy: 0.7822\n",
      "Epoch 68/100\n",
      "81200/81200 [==============================] - 21s 256us/step - loss: 0.5592 - accuracy: 0.7819\n",
      "Epoch 69/100\n",
      "81200/81200 [==============================] - 21s 254us/step - loss: 0.5586 - accuracy: 0.7841\n",
      "Epoch 70/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5561 - accuracy: 0.7838\n",
      "Epoch 71/100\n",
      "81200/81200 [==============================] - 20s 251us/step - loss: 0.5572 - accuracy: 0.7825\n",
      "Epoch 72/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5560 - accuracy: 0.7829\n",
      "Epoch 73/100\n",
      "81200/81200 [==============================] - 20s 250us/step - loss: 0.5584 - accuracy: 0.7833s - loss: 0.5564 -  - ETA: 0s - loss: 0.5\n",
      "Epoch 74/100\n",
      "81200/81200 [==============================] - 21s 254us/step - loss: 0.5577 - accuracy: 0.7826\n",
      "Epoch 75/100\n",
      "81200/81200 [==============================] - 21s 256us/step - loss: 0.5574 - accuracy: 0.7828s - loss: 0.5\n",
      "Epoch 76/100\n",
      "81200/81200 [==============================] - 20s 252us/step - loss: 0.5591 - accuracy: 0.7834\n",
      "Epoch 77/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5575 - accuracy: 0.7844\n",
      "Epoch 78/100\n",
      "81200/81200 [==============================] - 21s 257us/step - loss: 0.5567 - accuracy: 0.7830\n",
      "Epoch 79/100\n",
      "81200/81200 [==============================] - 20s 252us/step - loss: 0.5560 - accuracy: 0.7826\n",
      "Epoch 80/100\n",
      "81200/81200 [==============================] - 21s 259us/step - loss: 0.5556 - accuracy: 0.7839\n",
      "Epoch 81/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5530 - accuracy: 0.7841\n",
      "Epoch 82/100\n",
      "81200/81200 [==============================] - 21s 256us/step - loss: 0.5523 - accuracy: 0.7842\n",
      "Epoch 83/100\n",
      "81200/81200 [==============================] - 21s 259us/step - loss: 0.5519 - accuracy: 0.7842\n",
      "Epoch 84/100\n",
      "81200/81200 [==============================] - 21s 255us/step - loss: 0.5514 - accuracy: 0.7841\n",
      "Epoch 85/100\n",
      "81200/81200 [==============================] - 20s 252us/step - loss: 0.5545 - accuracy: 0.7837\n",
      "Epoch 86/100\n",
      "81200/81200 [==============================] - 21s 254us/step - loss: 0.5538 - accuracy: 0.7837s - loss: 0.5543 - accura - ETA: 0s - loss: 0.5534 - accuracy\n",
      "Epoch 87/100\n",
      "81200/81200 [==============================] - 21s 261us/step - loss: 0.5578 - accuracy: 0.7827s - loss: 0.5\n",
      "Epoch 88/100\n",
      "81200/81200 [==============================] - 20s 250us/step - loss: 0.5540 - accuracy: 0.7831\n",
      "Epoch 89/100\n",
      "81200/81200 [==============================] - 21s 253us/step - loss: 0.5554 - accuracy: 0.7843\n",
      "Epoch 90/100\n",
      "81200/81200 [==============================] - 21s 264us/step - loss: 0.5567 - accuracy: 0.7828\n",
      "Epoch 91/100\n",
      "81200/81200 [==============================] - 21s 256us/step - loss: 0.5543 - accuracy: 0.7835\n",
      "Epoch 92/100\n",
      "81200/81200 [==============================] - 20s 252us/step - loss: 0.5528 - accuracy: 0.7849\n",
      "Epoch 93/100\n",
      "81200/81200 [==============================] - 21s 262us/step - loss: 0.5545 - accuracy: 0.7846\n",
      "Epoch 94/100\n",
      "81200/81200 [==============================] - 21s 254us/step - loss: 0.5562 - accuracy: 0.7843\n",
      "Epoch 95/100\n",
      "81200/81200 [==============================] - 20s 252us/step - loss: 0.5537 - accuracy: 0.7846\n",
      "Epoch 96/100\n",
      "81200/81200 [==============================] - 21s 254us/step - loss: 0.5541 - accuracy: 0.7845\n",
      "Epoch 97/100\n",
      "81200/81200 [==============================] - 21s 261us/step - loss: 0.5522 - accuracy: 0.7859\n",
      "Epoch 98/100\n",
      "81200/81200 [==============================] - 19s 237us/step - loss: 0.5538 - accuracy: 0.7846\n",
      "Epoch 99/100\n",
      "81200/81200 [==============================] - 20s 248us/step - loss: 0.5560 - accuracy: 0.7841\n",
      "Epoch 100/100\n",
      "81200/81200 [==============================] - 19s 233us/step - loss: 0.5525 - accuracy: 0.7859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af3d7e0e80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising the Artificial Neural Network\n",
    "model = Sequential()\n",
    "#Creating the Input-layer and the first hidden layer\n",
    "model.add(Dense(300, input_dim=35, activation='sigmoid'))\n",
    "model.add(Dense(600, input_dim=35, activation='sigmoid'))\n",
    "model.add(Dense(600, input_dim=35, activation='sigmoid'))\n",
    "model.add(Dense(300, input_dim=35, activation='sigmoid'))\n",
    "#Creating the output  layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#Compiling the ANN classifier\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800/34800 [==============================] - 4s 103us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6244542399357105, 0.7737069129943848]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "predictions = model.predict(X_test)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71733668, 0.56230366, 0.3566879 , 0.65609158, 0.87564103,\n",
       "       0.99618598, 0.99986902, 0.77764706, 0.67027281, 0.94886076])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "con = metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "precision = np.diag(con) / (np.diag(con) +(con.sum(axis=0) - np.diag(con)))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32114736, 0.31440281, 0.58519594, 0.6381422 , 0.82322218,\n",
       "       0.98086552, 0.99973808, 0.56495726, 0.86311326, 1.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = np.diag(con)/ ((con.sum(axis=1) - np.diag(con)) + np.diag(con))\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44366744, 0.40330454, 0.44322304, 0.64699242, 0.8486229 ,\n",
       "       0.98846639, 0.99980355, 0.65445545, 0.75456712, 0.97375942])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CorrelationAttributeEval\n",
    "features = ['id','ct_dst_sport_ltm','ct_dst_src_ltm','ct_src_dport_ltm','sttl','ct_srv_dst','ct_srv_src','ct_dst_ltm','ct_src_ltm','ct_state_ttl','state','swin','dwin','proto','service','rate','dttl','stcpb','dtcpb','dmean','dload','tcprtt','ackdat','synack']\n",
    "X2 = df[['id','ct_dst_sport_ltm','ct_dst_src_ltm','ct_src_dport_ltm','sttl','ct_srv_dst','ct_srv_src','ct_dst_ltm','ct_src_ltm','ct_state_ttl','state','swin','dwin','proto','service','rate','dttl','stcpb','dtcpb','dmean','dload','tcprtt','ackdat','synack']]\n",
    "Y2 = df[['attack_cat']]\n",
    "X3 = X2.iloc[:,0:24]  #independent columns\n",
    "Y3 = Y2.iloc[:,-1]    #target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sScaler = StandardScaler()\n",
    "rescaleX3 = sScaler.fit_transform(X3)\n",
    "df_rescaled = pd.DataFrame(data=rescaleX3, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rescaleX3, Y3, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "81200/81200 [==============================] - 11s 139us/step - loss: 1.2281 - accuracy: 0.5415\n",
      "Epoch 2/100\n",
      "81200/81200 [==============================] - 11s 132us/step - loss: 1.0027 - accuracy: 0.6049\n",
      "Epoch 3/100\n",
      "81200/81200 [==============================] - 11s 135us/step - loss: 0.9415 - accuracy: 0.6268\n",
      "Epoch 4/100\n",
      "81200/81200 [==============================] - 11s 129us/step - loss: 0.9114 - accuracy: 0.6364\n",
      "Epoch 5/100\n",
      "81200/81200 [==============================] - 11s 135us/step - loss: 0.8906 - accuracy: 0.6430\n",
      "Epoch 6/100\n",
      "81200/81200 [==============================] - 12s 151us/step - loss: 0.8748 - accuracy: 0.6480\n",
      "Epoch 7/100\n",
      "81200/81200 [==============================] - 13s 164us/step - loss: 0.8614 - accuracy: 0.6532\n",
      "Epoch 8/100\n",
      "81200/81200 [==============================] - 13s 161us/step - loss: 0.8493 - accuracy: 0.6588\n",
      "Epoch 9/100\n",
      "81200/81200 [==============================] - 12s 148us/step - loss: 0.8359 - accuracy: 0.6629\n",
      "Epoch 10/100\n",
      "81200/81200 [==============================] - 12s 149us/step - loss: 0.8254 - accuracy: 0.6690\n",
      "Epoch 11/100\n",
      "81200/81200 [==============================] - 12s 147us/step - loss: 0.8171 - accuracy: 0.6728\n",
      "Epoch 12/100\n",
      "81200/81200 [==============================] - 12s 147us/step - loss: 0.8090 - accuracy: 0.6754\n",
      "Epoch 13/100\n",
      "81200/81200 [==============================] - 12s 151us/step - loss: 0.8035 - accuracy: 0.6775\n",
      "Epoch 14/100\n",
      "81200/81200 [==============================] - 11s 139us/step - loss: 0.7954 - accuracy: 0.6810\n",
      "Epoch 15/100\n",
      "81200/81200 [==============================] - 11s 140us/step - loss: 0.7915 - accuracy: 0.6822\n",
      "Epoch 16/100\n",
      "81200/81200 [==============================] - 11s 137us/step - loss: 0.7844 - accuracy: 0.6848\n",
      "Epoch 17/100\n",
      "81200/81200 [==============================] - 11s 138us/step - loss: 0.7786 - accuracy: 0.6886\n",
      "Epoch 18/100\n",
      "81200/81200 [==============================] - 11s 139us/step - loss: 0.7759 - accuracy: 0.6865\n",
      "Epoch 19/100\n",
      "81200/81200 [==============================] - 11s 141us/step - loss: 0.7702 - accuracy: 0.6904\n",
      "Epoch 20/100\n",
      "81200/81200 [==============================] - 12s 149us/step - loss: 0.7662 - accuracy: 0.6903\n",
      "Epoch 21/100\n",
      "81200/81200 [==============================] - 12s 147us/step - loss: 0.7615 - accuracy: 0.6934\n",
      "Epoch 22/100\n",
      "81200/81200 [==============================] - 12s 152us/step - loss: 0.7587 - accuracy: 0.6936\n",
      "Epoch 23/100\n",
      "81200/81200 [==============================] - 12s 145us/step - loss: 0.7566 - accuracy: 0.6943\n",
      "Epoch 24/100\n",
      "81200/81200 [==============================] - 12s 152us/step - loss: 0.7526 - accuracy: 0.6975\n",
      "Epoch 25/100\n",
      "81200/81200 [==============================] - 12s 144us/step - loss: 0.7491 - accuracy: 0.6964\n",
      "Epoch 26/100\n",
      "81200/81200 [==============================] - 12s 145us/step - loss: 0.7468 - accuracy: 0.6986\n",
      "Epoch 27/100\n",
      "81200/81200 [==============================] - 12s 144us/step - loss: 0.7437 - accuracy: 0.7000\n",
      "Epoch 28/100\n",
      "81200/81200 [==============================] - 12s 153us/step - loss: 0.7419 - accuracy: 0.7007\n",
      "Epoch 29/100\n",
      "81200/81200 [==============================] - 12s 146us/step - loss: 0.7376 - accuracy: 0.7014\n",
      "Epoch 30/100\n",
      "81200/81200 [==============================] - 12s 148us/step - loss: 0.7375 - accuracy: 0.7014\n",
      "Epoch 31/100\n",
      "81200/81200 [==============================] - 12s 150us/step - loss: 0.7336 - accuracy: 0.7039\n",
      "Epoch 32/100\n",
      "81200/81200 [==============================] - 12s 145us/step - loss: 0.7338 - accuracy: 0.7044\n",
      "Epoch 33/100\n",
      "81200/81200 [==============================] - 12s 149us/step - loss: 0.7302 - accuracy: 0.7038\n",
      "Epoch 34/100\n",
      "81200/81200 [==============================] - 12s 143us/step - loss: 0.7279 - accuracy: 0.7050\n",
      "Epoch 35/100\n",
      "81200/81200 [==============================] - 11s 141us/step - loss: 0.7239 - accuracy: 0.7064\n",
      "Epoch 36/100\n",
      "81200/81200 [==============================] - 11s 137us/step - loss: 0.7242 - accuracy: 0.7077\n",
      "Epoch 37/100\n",
      "81200/81200 [==============================] - 12s 143us/step - loss: 0.7230 - accuracy: 0.7075\n",
      "Epoch 38/100\n",
      "81200/81200 [==============================] - 11s 140us/step - loss: 0.7205 - accuracy: 0.7076\n",
      "Epoch 39/100\n",
      "81200/81200 [==============================] - 12s 149us/step - loss: 0.7197 - accuracy: 0.7092\n",
      "Epoch 40/100\n",
      "81200/81200 [==============================] - 12s 147us/step - loss: 0.7186 - accuracy: 0.7096\n",
      "Epoch 41/100\n",
      "81200/81200 [==============================] - 13s 165us/step - loss: 0.7159 - accuracy: 0.7111\n",
      "Epoch 42/100\n",
      "81200/81200 [==============================] - 13s 158us/step - loss: 0.7163 - accuracy: 0.7113\n",
      "Epoch 43/100\n",
      "81200/81200 [==============================] - 13s 160us/step - loss: 0.7153 - accuracy: 0.7118\n",
      "Epoch 44/100\n",
      "81200/81200 [==============================] - 13s 162us/step - loss: 0.7130 - accuracy: 0.7124\n",
      "Epoch 45/100\n",
      "81200/81200 [==============================] - 13s 164us/step - loss: 0.7119 - accuracy: 0.7122\n",
      "Epoch 46/100\n",
      "81200/81200 [==============================] - 15s 187us/step - loss: 0.7100 - accuracy: 0.7136\n",
      "Epoch 47/100\n",
      "81200/81200 [==============================] - 15s 185us/step - loss: 0.7095 - accuracy: 0.7125\n",
      "Epoch 48/100\n",
      "81200/81200 [==============================] - 14s 176us/step - loss: 0.7089 - accuracy: 0.7138\n",
      "Epoch 49/100\n",
      "81200/81200 [==============================] - 13s 159us/step - loss: 0.7072 - accuracy: 0.7153\n",
      "Epoch 50/100\n",
      "81200/81200 [==============================] - 14s 166us/step - loss: 0.7062 - accuracy: 0.7163\n",
      "Epoch 51/100\n",
      "81200/81200 [==============================] - 13s 160us/step - loss: 0.7048 - accuracy: 0.7152\n",
      "Epoch 52/100\n",
      "81200/81200 [==============================] - 13s 160us/step - loss: 0.7033 - accuracy: 0.7163\n",
      "Epoch 53/100\n",
      "81200/81200 [==============================] - 13s 155us/step - loss: 0.7048 - accuracy: 0.7151\n",
      "Epoch 54/100\n",
      "81200/81200 [==============================] - 12s 151us/step - loss: 0.6992 - accuracy: 0.7176\n",
      "Epoch 55/100\n",
      "81200/81200 [==============================] - 12s 150us/step - loss: 0.7021 - accuracy: 0.7173\n",
      "Epoch 56/100\n",
      "81200/81200 [==============================] - 12s 151us/step - loss: 0.7002 - accuracy: 0.7187\n",
      "Epoch 57/100\n",
      "81200/81200 [==============================] - 12s 153us/step - loss: 0.7006 - accuracy: 0.7187\n",
      "Epoch 58/100\n",
      "81200/81200 [==============================] - 12s 149us/step - loss: 0.7003 - accuracy: 0.7183\n",
      "Epoch 59/100\n",
      "81200/81200 [==============================] - 12s 153us/step - loss: 0.6996 - accuracy: 0.7167\n",
      "Epoch 60/100\n",
      "81200/81200 [==============================] - 13s 156us/step - loss: 0.7002 - accuracy: 0.7181\n",
      "Epoch 61/100\n",
      "81200/81200 [==============================] - 13s 156us/step - loss: 0.6987 - accuracy: 0.7187\n",
      "Epoch 62/100\n",
      "81200/81200 [==============================] - 12s 154us/step - loss: 0.6981 - accuracy: 0.7187\n",
      "Epoch 63/100\n",
      "81200/81200 [==============================] - 13s 156us/step - loss: 0.6981 - accuracy: 0.7188\n",
      "Epoch 64/100\n",
      "81200/81200 [==============================] - 13s 154us/step - loss: 0.6957 - accuracy: 0.7193\n",
      "Epoch 65/100\n",
      "81200/81200 [==============================] - 12s 150us/step - loss: 0.6997 - accuracy: 0.7196\n",
      "Epoch 66/100\n",
      "81200/81200 [==============================] - 12s 152us/step - loss: 0.6984 - accuracy: 0.7192\n",
      "Epoch 67/100\n",
      "81200/81200 [==============================] - 12s 146us/step - loss: 0.6955 - accuracy: 0.7205\n",
      "Epoch 68/100\n",
      "81200/81200 [==============================] - 12s 148us/step - loss: 0.6974 - accuracy: 0.7210\n",
      "Epoch 69/100\n",
      "81200/81200 [==============================] - 13s 155us/step - loss: 0.6987 - accuracy: 0.7183\n",
      "Epoch 70/100\n",
      "81200/81200 [==============================] - 12s 150us/step - loss: 0.6947 - accuracy: 0.7202\n",
      "Epoch 71/100\n",
      "81200/81200 [==============================] - 13s 156us/step - loss: 0.6961 - accuracy: 0.7210\n",
      "Epoch 72/100\n",
      "81200/81200 [==============================] - 13s 156us/step - loss: 0.6938 - accuracy: 0.7203\n",
      "Epoch 73/100\n",
      "81200/81200 [==============================] - 12s 150us/step - loss: 0.6959 - accuracy: 0.7227\n",
      "Epoch 74/100\n",
      "81200/81200 [==============================] - 12s 153us/step - loss: 0.6962 - accuracy: 0.7224\n",
      "Epoch 75/100\n",
      "81200/81200 [==============================] - 12s 147us/step - loss: 0.6967 - accuracy: 0.7211\n",
      "Epoch 76/100\n",
      "81200/81200 [==============================] - 12s 145us/step - loss: 0.6974 - accuracy: 0.7219\n",
      "Epoch 77/100\n",
      "81200/81200 [==============================] - 12s 143us/step - loss: 0.6955 - accuracy: 0.7215\n",
      "Epoch 78/100\n",
      "81200/81200 [==============================] - 12s 149us/step - loss: 0.6959 - accuracy: 0.7208\n",
      "Epoch 79/100\n",
      "81200/81200 [==============================] - 12s 151us/step - loss: 0.6972 - accuracy: 0.7209\n",
      "Epoch 80/100\n",
      "81200/81200 [==============================] - 12s 151us/step - loss: 0.6974 - accuracy: 0.7226\n",
      "Epoch 81/100\n",
      "81200/81200 [==============================] - 12s 144us/step - loss: 0.6964 - accuracy: 0.7205\n",
      "Epoch 82/100\n",
      "81200/81200 [==============================] - 13s 156us/step - loss: 0.6950 - accuracy: 0.7218\n",
      "Epoch 83/100\n",
      "81200/81200 [==============================] - 12s 147us/step - loss: 0.6951 - accuracy: 0.7213\n",
      "Epoch 84/100\n",
      "81200/81200 [==============================] - 13s 157us/step - loss: 0.6947 - accuracy: 0.7227\n",
      "Epoch 85/100\n",
      "81200/81200 [==============================] - 13s 154us/step - loss: 0.6969 - accuracy: 0.7213\n",
      "Epoch 86/100\n",
      "81200/81200 [==============================] - 12s 144us/step - loss: 0.6965 - accuracy: 0.7223\n",
      "Epoch 87/100\n",
      "81200/81200 [==============================] - 12s 149us/step - loss: 0.6962 - accuracy: 0.7211\n",
      "Epoch 88/100\n",
      "81200/81200 [==============================] - 12s 153us/step - loss: 0.6977 - accuracy: 0.7212\n",
      "Epoch 89/100\n",
      "81200/81200 [==============================] - 12s 151us/step - loss: 0.6966 - accuracy: 0.7225\n",
      "Epoch 90/100\n",
      "81200/81200 [==============================] - 12s 144us/step - loss: 0.6962 - accuracy: 0.7228\n",
      "Epoch 91/100\n",
      "81200/81200 [==============================] - 12s 153us/step - loss: 0.6981 - accuracy: 0.7229\n",
      "Epoch 92/100\n",
      "81200/81200 [==============================] - 13s 156us/step - loss: 0.6976 - accuracy: 0.7215\n",
      "Epoch 93/100\n",
      "81200/81200 [==============================] - 13s 159us/step - loss: 0.6977 - accuracy: 0.7226s - loss: 0.6978 - \n",
      "Epoch 94/100\n",
      "81200/81200 [==============================] - 11s 138us/step - loss: 0.6983 - accuracy: 0.7222\n",
      "Epoch 95/100\n",
      "81200/81200 [==============================] - 11s 141us/step - loss: 0.6981 - accuracy: 0.7227\n",
      "Epoch 96/100\n",
      "81200/81200 [==============================] - 12s 147us/step - loss: 0.7001 - accuracy: 0.7225\n",
      "Epoch 97/100\n",
      "81200/81200 [==============================] - 11s 138us/step - loss: 0.7017 - accuracy: 0.7216\n",
      "Epoch 98/100\n",
      "81200/81200 [==============================] - 12s 144us/step - loss: 0.6980 - accuracy: 0.7221\n",
      "Epoch 99/100\n",
      "81200/81200 [==============================] - 12s 144us/step - loss: 0.6993 - accuracy: 0.7216\n",
      "Epoch 100/100\n",
      "81200/81200 [==============================] - 11s 132us/step - loss: 0.7011 - accuracy: 0.7210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af483bdfd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising the Artificial Neural Network\n",
    "model = Sequential()\n",
    "#Creating the Input-layer and the first hidden layer\n",
    "model.add(Dense(200, input_dim=24, activation='sigmoid'))\n",
    "model.add(Dense(400, input_dim=24, activation='sigmoid'))\n",
    "model.add(Dense(400, input_dim=24, activation='sigmoid'))\n",
    "model.add(Dense(200, input_dim=24, activation='sigmoid'))\n",
    "#Creating the output  layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#Compiling the ANN classifier\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800/34800 [==============================] - 2s 66us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7400206503100779, 0.7176724076271057]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "predictions = model.predict(X_test)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69137168, 0.63551402, 0.34088702, 0.6137887 , 0.75759135,\n",
       "       0.99513163, 0.9383675 , 0.48097826, 0.64133219, 0.86979416])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "precision = np.diag(con) / (np.diag(con) +(con.sum(axis=0) - np.diag(con)))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34877232, 0.23475259, 0.61078886, 0.61822858, 0.59959267,\n",
       "       0.98080682, 0.96238736, 0.44305382, 0.45570388, 1.        ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = np.diag(con)/ ((con.sum(axis=1) - np.diag(con)) + np.diag(con))\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46364985, 0.34285714, 0.43756493, 0.61600064, 0.66939518,\n",
       "       0.9879173 , 0.95022566, 0.46123779, 0.53281305, 0.93036354])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PrincipalComponentAnalysis\n",
    "features = ['id','dur','dwin','proto','djit','swin','smean','state','service','ct_src_dport_ltm','ct_dst_ltm','ct_dst_sport_ltm','ct_src_ltm','ct_flw_http_mthd','ct_srv_dst','dpkts','dloss','dbytes','sttl','dmean','spkts','sbytes','sloss','sinpkt','label']\n",
    "X2 = df[['id','dur','dwin','proto','djit','swin','smean','state','service','ct_src_dport_ltm','ct_dst_ltm','ct_dst_sport_ltm','ct_src_ltm','ct_flw_http_mthd','ct_srv_dst','dpkts','dloss','dbytes','sttl','dmean','spkts','sbytes','sloss','sinpkt','label']]\n",
    "Y2 = df[['attack_cat']]\n",
    "X3 = X2.iloc[:,0:25]  #independent columns\n",
    "Y3 = Y2.iloc[:,-1]    #target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sScaler = StandardScaler()\n",
    "rescaleX3 = sScaler.fit_transform(X3)\n",
    "df_rescaled = pd.DataFrame(data=rescaleX3, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rescaleX3, Y3, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "81200/81200 [==============================] - 10s 119us/step - loss: 1.1038 - accuracy: 0.5826\n",
      "Epoch 2/100\n",
      "81200/81200 [==============================] - 9s 105us/step - loss: 0.8727 - accuracy: 0.6519\n",
      "Epoch 3/100\n",
      "81200/81200 [==============================] - 10s 117us/step - loss: 0.8127 - accuracy: 0.6789\n",
      "Epoch 4/100\n",
      "81200/81200 [==============================] - 12s 150us/step - loss: 0.7765 - accuracy: 0.6926\n",
      "Epoch 5/100\n",
      "81200/81200 [==============================] - 10s 120us/step - loss: 0.7416 - accuracy: 0.7069\n",
      "Epoch 6/100\n",
      "81200/81200 [==============================] - 9s 117us/step - loss: 0.7085 - accuracy: 0.7161\n",
      "Epoch 7/100\n",
      "81200/81200 [==============================] - 10s 125us/step - loss: 0.6870 - accuracy: 0.7243\n",
      "Epoch 8/100\n",
      "81200/81200 [==============================] - 10s 126us/step - loss: 0.6745 - accuracy: 0.7287\n",
      "Epoch 9/100\n",
      "81200/81200 [==============================] - 10s 127us/step - loss: 0.6643 - accuracy: 0.7346\n",
      "Epoch 10/100\n",
      "81200/81200 [==============================] - 10s 128us/step - loss: 0.6570 - accuracy: 0.7363\n",
      "Epoch 11/100\n",
      "81200/81200 [==============================] - 10s 127us/step - loss: 0.6519 - accuracy: 0.7390\n",
      "Epoch 12/100\n",
      "81200/81200 [==============================] - 10s 117us/step - loss: 0.6476 - accuracy: 0.7400\n",
      "Epoch 13/100\n",
      "81200/81200 [==============================] - 10s 125us/step - loss: 0.6439 - accuracy: 0.7406\n",
      "Epoch 14/100\n",
      "81200/81200 [==============================] - 9s 116us/step - loss: 0.6406 - accuracy: 0.7436\n",
      "Epoch 15/100\n",
      "81200/81200 [==============================] - 10s 121us/step - loss: 0.6349 - accuracy: 0.7451\n",
      "Epoch 16/100\n",
      "81200/81200 [==============================] - 12s 148us/step - loss: 0.6321 - accuracy: 0.7461\n",
      "Epoch 17/100\n",
      "81200/81200 [==============================] - 11s 136us/step - loss: 0.6271 - accuracy: 0.7488\n",
      "Epoch 18/100\n",
      "81200/81200 [==============================] - 10s 128us/step - loss: 0.6249 - accuracy: 0.7496\n",
      "Epoch 19/100\n",
      "81200/81200 [==============================] - 10s 119us/step - loss: 0.6206 - accuracy: 0.7522\n",
      "Epoch 20/100\n",
      "81200/81200 [==============================] - 9s 112us/step - loss: 0.6173 - accuracy: 0.7542\n",
      "Epoch 21/100\n",
      "81200/81200 [==============================] - 9s 113us/step - loss: 0.6147 - accuracy: 0.7553\n",
      "Epoch 22/100\n",
      "81200/81200 [==============================] - 10s 127us/step - loss: 0.6121 - accuracy: 0.7564\n",
      "Epoch 23/100\n",
      "81200/81200 [==============================] - 10s 123us/step - loss: 0.6080 - accuracy: 0.7589\n",
      "Epoch 24/100\n",
      "81200/81200 [==============================] - 11s 139us/step - loss: 0.6067 - accuracy: 0.7589\n",
      "Epoch 25/100\n",
      "81200/81200 [==============================] - 14s 172us/step - loss: 0.6037 - accuracy: 0.7605\n",
      "Epoch 26/100\n",
      "81200/81200 [==============================] - 12s 147us/step - loss: 0.6013 - accuracy: 0.7598\n",
      "Epoch 27/100\n",
      "81200/81200 [==============================] - 10s 119us/step - loss: 0.6008 - accuracy: 0.7619\n",
      "Epoch 28/100\n",
      "81200/81200 [==============================] - 9s 117us/step - loss: 0.5982 - accuracy: 0.7639\n",
      "Epoch 29/100\n",
      "81200/81200 [==============================] - 11s 140us/step - loss: 0.5974 - accuracy: 0.7629\n",
      "Epoch 30/100\n",
      "81200/81200 [==============================] - 11s 139us/step - loss: 0.5957 - accuracy: 0.7654\n",
      "Epoch 31/100\n",
      "81200/81200 [==============================] - 9s 115us/step - loss: 0.5921 - accuracy: 0.7663\n",
      "Epoch 32/100\n",
      "81200/81200 [==============================] - 9s 115us/step - loss: 0.5933 - accuracy: 0.7653\n",
      "Epoch 33/100\n",
      "81200/81200 [==============================] - 10s 121us/step - loss: 0.5908 - accuracy: 0.7670\n",
      "Epoch 34/100\n",
      "81200/81200 [==============================] - 10s 124us/step - loss: 0.5888 - accuracy: 0.7679\n",
      "Epoch 35/100\n",
      "81200/81200 [==============================] - 10s 120us/step - loss: 0.5889 - accuracy: 0.7683\n",
      "Epoch 36/100\n",
      "81200/81200 [==============================] - 10s 121us/step - loss: 0.5863 - accuracy: 0.7698\n",
      "Epoch 37/100\n",
      "81200/81200 [==============================] - 9s 114us/step - loss: 0.5847 - accuracy: 0.7703\n",
      "Epoch 38/100\n",
      "81200/81200 [==============================] - 9s 116us/step - loss: 0.5815 - accuracy: 0.7700\n",
      "Epoch 39/100\n",
      "81200/81200 [==============================] - 13s 164us/step - loss: 0.5826 - accuracy: 0.7704\n",
      "Epoch 40/100\n",
      "81200/81200 [==============================] - 12s 154us/step - loss: 0.5823 - accuracy: 0.7707\n",
      "Epoch 41/100\n",
      "81200/81200 [==============================] - 12s 149us/step - loss: 0.5802 - accuracy: 0.7723\n",
      "Epoch 42/100\n",
      "81200/81200 [==============================] - 11s 133us/step - loss: 0.5783 - accuracy: 0.7719\n",
      "Epoch 43/100\n",
      "81200/81200 [==============================] - 10s 129us/step - loss: 0.5792 - accuracy: 0.7729\n",
      "Epoch 44/100\n",
      "81200/81200 [==============================] - 11s 130us/step - loss: 0.5800 - accuracy: 0.7718\n",
      "Epoch 45/100\n",
      "81200/81200 [==============================] - 11s 130us/step - loss: 0.5793 - accuracy: 0.7728\n",
      "Epoch 46/100\n",
      "81200/81200 [==============================] - 12s 147us/step - loss: 0.5784 - accuracy: 0.7728\n",
      "Epoch 47/100\n",
      "81200/81200 [==============================] - 10s 127us/step - loss: 0.5781 - accuracy: 0.7721\n",
      "Epoch 48/100\n",
      "81200/81200 [==============================] - 10s 123us/step - loss: 0.5783 - accuracy: 0.7728\n",
      "Epoch 49/100\n",
      "81200/81200 [==============================] - 10s 119us/step - loss: 0.5773 - accuracy: 0.7730\n",
      "Epoch 50/100\n",
      "81200/81200 [==============================] - 10s 123us/step - loss: 0.5779 - accuracy: 0.7731\n",
      "Epoch 51/100\n",
      "81200/81200 [==============================] - 10s 124us/step - loss: 0.5762 - accuracy: 0.7746\n",
      "Epoch 52/100\n",
      "81200/81200 [==============================] - 10s 120us/step - loss: 0.5786 - accuracy: 0.7746\n",
      "Epoch 53/100\n",
      "81200/81200 [==============================] - 10s 127us/step - loss: 0.5769 - accuracy: 0.7742\n",
      "Epoch 54/100\n",
      "81200/81200 [==============================] - 11s 135us/step - loss: 0.5756 - accuracy: 0.7747\n",
      "Epoch 55/100\n",
      "81200/81200 [==============================] - 13s 155us/step - loss: 0.5765 - accuracy: 0.7742\n",
      "Epoch 56/100\n",
      "81200/81200 [==============================] - 12s 153us/step - loss: 0.5753 - accuracy: 0.7762\n",
      "Epoch 57/100\n",
      "81200/81200 [==============================] - 12s 148us/step - loss: 0.5731 - accuracy: 0.7764\n",
      "Epoch 58/100\n",
      "81200/81200 [==============================] - 10s 124us/step - loss: 0.5737 - accuracy: 0.7752\n",
      "Epoch 59/100\n",
      "81200/81200 [==============================] - 11s 130us/step - loss: 0.5731 - accuracy: 0.7754\n",
      "Epoch 60/100\n",
      "81200/81200 [==============================] - 14s 167us/step - loss: 0.5728 - accuracy: 0.7759\n",
      "Epoch 61/100\n",
      "81200/81200 [==============================] - 10s 129us/step - loss: 0.5734 - accuracy: 0.7765\n",
      "Epoch 62/100\n",
      "81200/81200 [==============================] - 11s 137us/step - loss: 0.5724 - accuracy: 0.7752\n",
      "Epoch 63/100\n",
      "81200/81200 [==============================] - 11s 131us/step - loss: 0.5729 - accuracy: 0.7761\n",
      "Epoch 64/100\n",
      "81200/81200 [==============================] - 11s 132us/step - loss: 0.5719 - accuracy: 0.7768\n",
      "Epoch 65/100\n",
      "81200/81200 [==============================] - 9s 116us/step - loss: 0.5701 - accuracy: 0.7771\n",
      "Epoch 66/100\n",
      "81200/81200 [==============================] - 10s 118us/step - loss: 0.5688 - accuracy: 0.7776\n",
      "Epoch 67/100\n",
      "81200/81200 [==============================] - 11s 141us/step - loss: 0.5706 - accuracy: 0.7765\n",
      "Epoch 68/100\n",
      "81200/81200 [==============================] - 12s 148us/step - loss: 0.5678 - accuracy: 0.7775\n",
      "Epoch 69/100\n",
      "81200/81200 [==============================] - 10s 129us/step - loss: 0.5721 - accuracy: 0.7773\n",
      "Epoch 70/100\n",
      "81200/81200 [==============================] - 10s 126us/step - loss: 0.5700 - accuracy: 0.7776\n",
      "Epoch 71/100\n",
      "81200/81200 [==============================] - 11s 130us/step - loss: 0.5734 - accuracy: 0.7776\n",
      "Epoch 72/100\n",
      "81200/81200 [==============================] - 10s 129us/step - loss: 0.5726 - accuracy: 0.7779\n",
      "Epoch 73/100\n",
      "81200/81200 [==============================] - 10s 119us/step - loss: 0.5735 - accuracy: 0.7774\n",
      "Epoch 74/100\n",
      "81200/81200 [==============================] - 9s 117us/step - loss: 0.5716 - accuracy: 0.7783\n",
      "Epoch 75/100\n",
      "81200/81200 [==============================] - 9s 114us/step - loss: 0.5745 - accuracy: 0.7767\n",
      "Epoch 76/100\n",
      "81200/81200 [==============================] - 9s 115us/step - loss: 0.5736 - accuracy: 0.7776\n",
      "Epoch 77/100\n",
      "81200/81200 [==============================] - 9s 114us/step - loss: 0.5704 - accuracy: 0.7773\n",
      "Epoch 78/100\n",
      "81200/81200 [==============================] - 10s 122us/step - loss: 0.5746 - accuracy: 0.7778\n",
      "Epoch 79/100\n",
      "81200/81200 [==============================] - 10s 128us/step - loss: 0.5738 - accuracy: 0.7772\n",
      "Epoch 80/100\n",
      "81200/81200 [==============================] - 10s 127us/step - loss: 0.5745 - accuracy: 0.7788\n",
      "Epoch 81/100\n",
      "81200/81200 [==============================] - 10s 129us/step - loss: 0.5745 - accuracy: 0.7775\n",
      "Epoch 82/100\n",
      "81200/81200 [==============================] - 11s 129us/step - loss: 0.5709 - accuracy: 0.7784\n",
      "Epoch 83/100\n",
      "81200/81200 [==============================] - 10s 121us/step - loss: 0.5730 - accuracy: 0.7779\n",
      "Epoch 84/100\n",
      "81200/81200 [==============================] - 10s 126us/step - loss: 0.5767 - accuracy: 0.7783\n",
      "Epoch 85/100\n",
      "81200/81200 [==============================] - 10s 126us/step - loss: 0.5738 - accuracy: 0.7784\n",
      "Epoch 86/100\n",
      "81200/81200 [==============================] - 11s 134us/step - loss: 0.5727 - accuracy: 0.7780\n",
      "Epoch 87/100\n",
      "81200/81200 [==============================] - 10s 129us/step - loss: 0.5711 - accuracy: 0.7786\n",
      "Epoch 88/100\n",
      "81200/81200 [==============================] - 9s 114us/step - loss: 0.5752 - accuracy: 0.7776\n",
      "Epoch 89/100\n",
      "81200/81200 [==============================] - 10s 128us/step - loss: 0.5755 - accuracy: 0.7785\n",
      "Epoch 90/100\n",
      "81200/81200 [==============================] - 9s 114us/step - loss: 0.5725 - accuracy: 0.7771\n",
      "Epoch 91/100\n",
      "81200/81200 [==============================] - 10s 119us/step - loss: 0.5732 - accuracy: 0.7781\n",
      "Epoch 92/100\n",
      "81200/81200 [==============================] - 10s 120us/step - loss: 0.5737 - accuracy: 0.7777\n",
      "Epoch 93/100\n",
      "81200/81200 [==============================] - 10s 125us/step - loss: 0.5756 - accuracy: 0.7757\n",
      "Epoch 94/100\n",
      "81200/81200 [==============================] - 11s 134us/step - loss: 0.5760 - accuracy: 0.7776\n",
      "Epoch 95/100\n",
      "81200/81200 [==============================] - 11s 130us/step - loss: 0.5757 - accuracy: 0.7785\n",
      "Epoch 96/100\n",
      "81200/81200 [==============================] - 10s 126us/step - loss: 0.5754 - accuracy: 0.7770\n",
      "Epoch 97/100\n",
      "81200/81200 [==============================] - 11s 141us/step - loss: 0.5745 - accuracy: 0.7777\n",
      "Epoch 98/100\n",
      "81200/81200 [==============================] - 11s 133us/step - loss: 0.5769 - accuracy: 0.7780\n",
      "Epoch 99/100\n",
      "81200/81200 [==============================] - 11s 131us/step - loss: 0.5751 - accuracy: 0.7779\n",
      "Epoch 100/100\n",
      "81200/81200 [==============================] - 11s 132us/step - loss: 0.5767 - accuracy: 0.7771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af4bbdc2b0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising the Artificial Neural Network\n",
    "model = Sequential()\n",
    "#Creating the Input-layer and the first hidden layer\n",
    "model.add(Dense(250, input_dim=25, activation='sigmoid'))\n",
    "model.add(Dense(500, input_dim=25, activation='sigmoid'))\n",
    "model.add(Dense(500, input_dim=25, activation='sigmoid'))\n",
    "model.add(Dense(250, input_dim=25, activation='sigmoid'))\n",
    "#Creating the output  layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#Compiling the ANN classifier\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.76865584e-07, 1.41635176e-03, 1.49118630e-02, ...,\n",
       "        6.61594450e-01, 6.51450595e-12, 5.93226605e-06],\n",
       "       [3.30842818e-28, 4.10127745e-27, 4.14147878e-19, ...,\n",
       "        8.56741773e-19, 8.96312044e-24, 2.12786305e-25],\n",
       "       [2.28544596e-30, 8.62110416e-30, 4.82734592e-19, ...,\n",
       "        3.23158732e-23, 7.76865960e-24, 1.59759648e-26],\n",
       "       ...,\n",
       "       [1.05090339e-05, 4.83202923e-04, 1.71450188e-03, ...,\n",
       "        9.80655193e-01, 1.32494085e-02, 2.74616219e-09],\n",
       "       [1.41561434e-01, 2.56661445e-01, 2.85265744e-01, ...,\n",
       "        3.97389866e-02, 7.55030953e-04, 8.34661265e-08],\n",
       "       [4.37267119e-07, 1.45802915e-05, 2.07709789e-04, ...,\n",
       "        1.08573636e-06, 1.15381233e-08, 9.98149276e-01]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800/34800 [==============================] - 1s 39us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5907803846638778, 0.7761494517326355]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>516</td>\n",
       "      <td>154</td>\n",
       "      <td>857</td>\n",
       "      <td>263</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>611</td>\n",
       "      <td>855</td>\n",
       "      <td>210</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>156</td>\n",
       "      <td>2065</td>\n",
       "      <td>1014</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>196</td>\n",
       "      <td>1597</td>\n",
       "      <td>4009</td>\n",
       "      <td>150</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>62</td>\n",
       "      <td>48</td>\n",
       "      <td>6248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>5431</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>280</td>\n",
       "      <td>263</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1483</td>\n",
       "      <td>153</td>\n",
       "      <td>14</td>\n",
       "      <td>2387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>106</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1321</td>\n",
       "      <td>13</td>\n",
       "      <td>1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1868</td>\n",
       "      <td>1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>674</td>\n",
       "      <td>1165</td>\n",
       "      <td>5834</td>\n",
       "      <td>6025</td>\n",
       "      <td>2573</td>\n",
       "      <td>5438</td>\n",
       "      <td>7723</td>\n",
       "      <td>1726</td>\n",
       "      <td>1678</td>\n",
       "      <td>1964</td>\n",
       "      <td>34800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0     1     2     3     4     5     6     7     8     9    All\n",
       "True                                                                       \n",
       "0          516   154   857   263     6     0     0     0     0     0   1796\n",
       "1            8   611   855   210    39     0     0    15    23     3   1764\n",
       "2           40   156  2065  1014    64     0     0    15    39     7   3400\n",
       "3           94   196  1597  4009   150     7     0    85    62    48   6248\n",
       "4            8    14   129   129  1985     0     2    44    79     9   2399\n",
       "5            1     2    45    31    11  5431     0     1     1     2   5525\n",
       "6            0     0     0     0     0     0  7721     0     0     0   7721\n",
       "7            7    32   280   263   155     0     0  1483   153    14   2387\n",
       "8            0     0     6   106   163     0     0    83  1321    13   1692\n",
       "9            0     0     0     0     0     0     0     0     0  1868   1868\n",
       "All        674  1165  5834  6025  2573  5438  7723  1726  1678  1964  34800"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test.argmax(axis=1), predictions.argmax(axis=1), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 516,  154,  857,  263,    6,    0,    0,    0,    0,    0],\n",
       "       [   8,  611,  855,  210,   39,    0,    0,   15,   23,    3],\n",
       "       [  40,  156, 2065, 1014,   64,    0,    0,   15,   39,    7],\n",
       "       [  94,  196, 1597, 4009,  150,    7,    0,   85,   62,   48],\n",
       "       [   8,   14,  129,  129, 1985,    0,    2,   44,   79,    9],\n",
       "       [   1,    2,   45,   31,   11, 5431,    0,    1,    1,    2],\n",
       "       [   0,    0,    0,    0,    0,    0, 7721,    0,    0,    0],\n",
       "       [   7,   32,  280,  263,  155,    0,    0, 1483,  153,   14],\n",
       "       [   0,    0,    6,  106,  163,    0,    0,   83, 1321,   13],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 1868]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76557864, 0.52446352, 0.35395955, 0.66539419, 0.77147299,\n",
       "       0.99871276, 0.99974103, 0.85921205, 0.78724672, 0.95112016])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = np.diag(con) / (np.diag(con) +(con.sum(axis=0) - np.diag(con)))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28730512, 0.34637188, 0.60735294, 0.64164533, 0.8274281 ,\n",
       "       0.98298643, 1.        , 0.62128194, 0.78073286, 1.        ])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = np.diag(con)/ ((con.sum(axis=1) - np.diag(con)) + np.diag(con))\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41781377, 0.41720724, 0.44726013, 0.653304  , 0.79847144,\n",
       "       0.99078719, 0.9998705 , 0.72112813, 0.78397626, 0.97494781])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
